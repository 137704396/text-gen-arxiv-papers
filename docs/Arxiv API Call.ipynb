{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import feedparser\n",
    "import atoma\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://export.arxiv.org/api/query?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query_story = '%28abs:\"text%20generation\"+OR+abs:\"natural%20language%20generation\"%29+AND+%28abs:narrative+OR+abs:story+OR+abs:fiction+OR+abs:plot%29'\n",
    "\n",
    "search_query_tables = '%28abs:\"text%20generation\"+OR+abs:\"natural%20language%20generation\"%29+AND+%28abs:tables+OR+abs:data+OR+abs:structured+OR+abs:table-to-text%29'\n",
    "\n",
    "search_query_games = '%28abs:\"text%20generation\"+OR+abs:\"natural%20language%20generation\"%29+AND+abs:games'\n",
    "\n",
    "search_query_knowledge = '%28abs:\"text%20generation\"+OR+abs:\"natural%20language%20generation\"%29+AND+%28abs:knowledge+OR+abs:graphs+OR+abs:semantics%29'\n",
    "\n",
    "search_query_poetry = '%28abs:\"text%20generation\"+OR+abs:\"natural%20language%20generation\"%29+AND+%28abs:poetry+OR+abs:poems+OR+abs:lyrics%29'\n",
    "\n",
    "search_query_dialogue = '%28abs:\"text%20generation\"+OR+abs:\"natural%20language%20generation\"%29+AND+%28abs:dialogue+OR+abs:agents+OR+abs:conversation%29'\n",
    "\n",
    "search_query_images = '%28abs:\"text%20generation\"+OR+abs:\"natural%20language%20generation\"%29+AND+%28abs:images+OR+abs:image2text+OR+abs:description+OR+abs:image-to-text+OR+abs:caption%29'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\"story\": search_query_story, \n",
    "           \"tables\": search_query_tables, \n",
    "           \"games\": search_query_games, \n",
    "           \"dialog\": search_query_dialogue, \n",
    "           \"knowledge\": search_query_knowledge, \n",
    "           \"poetry\": search_query_poetry, \n",
    "           \"image2text\": search_query_images}\n",
    "\n",
    "sort = \"&sortBy=lastUpdatedDate&sortOrder=descending\"\n",
    "\n",
    "start = 0                     # retreive the first 5 results\n",
    "max_results = 200\n",
    "#query = 'search_query=%s&start=%i&max_results=%i' % (query,\n",
    "                                                    # start,\n",
    "                                                     #max_results) + sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http%3A//export.arxiv.org/api/query%3Fsearch_query%3Dabs%3A%22text%2520generation%22AND%2528abs%3AdialogueORabs%3Aagents%2529%26start%3D0%26max_results%3D50%26sortBy%3DlastUpdatedDate%26sortOrder%3Ddescending'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "urllib.parse.quote(base_url + query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
    "#feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
    "\n",
    "# perform a GET request using the base_url and query\n",
    "response = urllib.request.urlopen(base_url+query).read()\n",
    "\n",
    "# parse the response using feedparser\n",
    "feed = feedparser.parse(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bozo', 'entries', 'feed', 'headers', 'encoding', 'version', 'namespaces'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bozo': False,\n",
       " 'entries': [{'id': 'http://arxiv.org/abs/2101.02690v1',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2101.02690v1',\n",
       "   'updated': '2021-01-07T18:52:08Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=18, tm_min=52, tm_sec=8, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2021-01-07T18:52:08Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=18, tm_min=52, tm_sec=8, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'title': 'Theorem Proving and Algebra',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Theorem Proving and Algebra'},\n",
       "   'summary': 'This book can be seen either as a text on theorem proving that uses\\ntechniques from general algebra, or else as a text on general algebra\\nillustrated and made concrete by practical exercises in theorem proving. The\\nbook considers several different logical systems, including first-order logic,\\nHorn clause logic, equational logic, and first-order logic with equality.\\nSimilarly, several different proof paradigms are considered. However, we do\\nemphasize equational logic, and for simplicity we use only the OBJ3 software\\nsystem, though it is used in a rather flexible manner. We do not pursue the\\nlofty goal of mechanizing proofs like those of which mathematicians are justly\\nso proud; instead, we seek to take steps towards providing mechanical\\nassistance for proofs that are useful for computer scientists in developing\\nsoftware and hardware. This more modest goal has the advantage of both being\\nachievable and having practical benefits.\\n  The following topics are covered: many-sorted signature, algebra and\\nhomomorphism; term algebra and substitution; equation and satisfaction;\\nconditional equations; equational deduction and its completeness; deduction for\\nconditional equations; the theorem of constants; interpretation and equivalence\\nof theories; term rewriting, termination, confluence and normal form; abstract\\nrewrite systems; standard models, abstract data types, initiality, and\\ninduction; rewriting and deduction modulo equations; first-order logic, models,\\nand proof planning; second-order algebra; order-sorted algebra and rewriting;\\nmodules; unification and completion; and hidden algebra. In parallel with these\\nare a gradual introduction to OBJ3, applications to group theory, various\\nabstract data types (such as number systems, lists, and stacks), propositional\\ncalculus, hardware verification, the {\\\\lambda}-calculus, correctness of\\nfunctional programs, and other topics.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'This book can be seen either as a text on theorem proving that uses\\ntechniques from general algebra, or else as a text on general algebra\\nillustrated and made concrete by practical exercises in theorem proving. The\\nbook considers several different logical systems, including first-order logic,\\nHorn clause logic, equational logic, and first-order logic with equality.\\nSimilarly, several different proof paradigms are considered. However, we do\\nemphasize equational logic, and for simplicity we use only the OBJ3 software\\nsystem, though it is used in a rather flexible manner. We do not pursue the\\nlofty goal of mechanizing proofs like those of which mathematicians are justly\\nso proud; instead, we seek to take steps towards providing mechanical\\nassistance for proofs that are useful for computer scientists in developing\\nsoftware and hardware. This more modest goal has the advantage of both being\\nachievable and having practical benefits.\\n  The following topics are covered: many-sorted signature, algebra and\\nhomomorphism; term algebra and substitution; equation and satisfaction;\\nconditional equations; equational deduction and its completeness; deduction for\\nconditional equations; the theorem of constants; interpretation and equivalence\\nof theories; term rewriting, termination, confluence and normal form; abstract\\nrewrite systems; standard models, abstract data types, initiality, and\\ninduction; rewriting and deduction modulo equations; first-order logic, models,\\nand proof planning; second-order algebra; order-sorted algebra and rewriting;\\nmodules; unification and completion; and hidden algebra. In parallel with these\\nare a gradual introduction to OBJ3, applications to group theory, various\\nabstract data types (such as number systems, lists, and stacks), propositional\\ncalculus, hardware verification, the {\\\\lambda}-calculus, correctness of\\nfunctional programs, and other topics.'},\n",
       "   'authors': [{'name': 'Joseph A. Goguen'}],\n",
       "   'author_detail': {'name': 'Joseph A. Goguen'},\n",
       "   'author': 'Joseph A. Goguen',\n",
       "   'arxiv_comment': \"427+ xviii pages, 38 figures, Unfinished book by Joseph A. Goguen,\\n  Edited by Kokichi Futatsugi, Narciso Mart\\\\'i-Oliet and Jos\\\\'e Meseguer\",\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2101.02690v1',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2101.02690v1',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.LO',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.LO',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': 'cs.PL',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': 'cs.SC',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': '68Q65, 03B70 (Primary)',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': 'F.3.1; F.3.2; F.4.1; F.1.1; I.1.3',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]},\n",
       "  {'id': 'http://arxiv.org/abs/2101.02483v1',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2101.02483v1',\n",
       "   'updated': '2021-01-07T11:03:07Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=11, tm_min=3, tm_sec=7, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2021-01-07T11:03:07Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=11, tm_min=3, tm_sec=7, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'title': 'Robust Text CAPTCHAs Using Adversarial Examples',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Robust Text CAPTCHAs Using Adversarial Examples'},\n",
       "   'summary': 'CAPTCHA (Completely Automated Public Truing test to tell Computers and Humans\\nApart) is a widely used technology to distinguish real users and automated\\nusers such as bots. However, the advance of AI technologies weakens many\\nCAPTCHA tests and can induce security concerns. In this paper, we propose a\\nuser-friendly text-based CAPTCHA generation method named Robust Text CAPTCHA\\n(RTC). At the first stage, the foregrounds and backgrounds are constructed with\\nrandomly sampled font and background images, which are then synthesized into\\nidentifiable pseudo adversarial CAPTCHAs. At the second stage, we design and\\napply a highly transferable adversarial attack for text CAPTCHAs to better\\nobstruct CAPTCHA solvers. Our experiments cover comprehensive models including\\nshallow models such as KNN, SVM and random forest, various deep neural networks\\nand OCR models. Experiments show that our CAPTCHAs have a failure rate lower\\nthan one millionth in general and high usability. They are also robust against\\nvarious defensive techniques that attackers may employ, including adversarial\\ntraining, data pre-processing and manual tagging.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'CAPTCHA (Completely Automated Public Truing test to tell Computers and Humans\\nApart) is a widely used technology to distinguish real users and automated\\nusers such as bots. However, the advance of AI technologies weakens many\\nCAPTCHA tests and can induce security concerns. In this paper, we propose a\\nuser-friendly text-based CAPTCHA generation method named Robust Text CAPTCHA\\n(RTC). At the first stage, the foregrounds and backgrounds are constructed with\\nrandomly sampled font and background images, which are then synthesized into\\nidentifiable pseudo adversarial CAPTCHAs. At the second stage, we design and\\napply a highly transferable adversarial attack for text CAPTCHAs to better\\nobstruct CAPTCHA solvers. Our experiments cover comprehensive models including\\nshallow models such as KNN, SVM and random forest, various deep neural networks\\nand OCR models. Experiments show that our CAPTCHAs have a failure rate lower\\nthan one millionth in general and high usability. They are also robust against\\nvarious defensive techniques that attackers may employ, including adversarial\\ntraining, data pre-processing and manual tagging.'},\n",
       "   'authors': [{'name': 'Rulin Shao'},\n",
       "    {'name': 'Zhouxing Shi'},\n",
       "    {'name': 'Jinfeng Yi'},\n",
       "    {'name': 'Pin-Yu Chen'},\n",
       "    {'name': 'Cho-Jui Hsieh'}],\n",
       "   'author_detail': {'name': 'Cho-Jui Hsieh'},\n",
       "   'author': 'Cho-Jui Hsieh',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2101.02483v1',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2101.02483v1',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.LG',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': 'cs.CV',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]},\n",
       "  {'id': 'http://arxiv.org/abs/2010.12284v2',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2010.12284v2',\n",
       "   'updated': '2021-01-07T10:39:57Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=10, tm_min=39, tm_sec=57, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2020-10-23T10:30:24Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=10, tm_mday=23, tm_hour=10, tm_min=30, tm_sec=24, tm_wday=4, tm_yday=297, tm_isdst=0),\n",
       "   'title': 'Pre-training Graph Transformer with Multimodal Side Information for\\n  Recommendation',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Pre-training Graph Transformer with Multimodal Side Information for\\n  Recommendation'},\n",
       "   'summary': 'Side information of items, e.g., images and text description, has shown to be\\neffective in contributing to accurate recommendations. Inspired by the recent\\nsuccess of pre-training models on natural language and images, we propose a\\npre-training strategy to learn item representations by considering both item\\nside information and their relationships. We relate items by common user\\nactivities, e.g., co-purchase, and construct a homogeneous item graph. This\\ngraph provides a unified view of item relations and their associated side\\ninformation in multimodality. We develop a novel sampling algorithm named\\nMCNSampling to select contextual neighbors for each item. The proposed\\nPre-trained Multimodal Graph Transformer (PMGT) learns item representations\\nwith two objectives: 1) graph structure reconstruction, and 2) masked node\\nfeature reconstruction. Experimental results on real datasets demonstrate that\\nthe proposed PMGT model effectively exploits the multimodality side information\\nto achieve better accuracies in downstream tasks including item recommendation,\\nitem classification, and click-through ratio prediction. We also report a case\\nstudy of testing the proposed PMGT model in an online setting with 600 thousand\\nusers.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Side information of items, e.g., images and text description, has shown to be\\neffective in contributing to accurate recommendations. Inspired by the recent\\nsuccess of pre-training models on natural language and images, we propose a\\npre-training strategy to learn item representations by considering both item\\nside information and their relationships. We relate items by common user\\nactivities, e.g., co-purchase, and construct a homogeneous item graph. This\\ngraph provides a unified view of item relations and their associated side\\ninformation in multimodality. We develop a novel sampling algorithm named\\nMCNSampling to select contextual neighbors for each item. The proposed\\nPre-trained Multimodal Graph Transformer (PMGT) learns item representations\\nwith two objectives: 1) graph structure reconstruction, and 2) masked node\\nfeature reconstruction. Experimental results on real datasets demonstrate that\\nthe proposed PMGT model effectively exploits the multimodality side information\\nto achieve better accuracies in downstream tasks including item recommendation,\\nitem classification, and click-through ratio prediction. We also report a case\\nstudy of testing the proposed PMGT model in an online setting with 600 thousand\\nusers.'},\n",
       "   'authors': [{'name': 'Yong Liu'},\n",
       "    {'name': 'Susen Yang'},\n",
       "    {'name': 'Chenyi Lei'},\n",
       "    {'name': 'Guoxin Wang'},\n",
       "    {'name': 'Haihong Tang'},\n",
       "    {'name': 'Juyong Zhang'},\n",
       "    {'name': 'Aixin Sun'},\n",
       "    {'name': 'Chunyan Miao'}],\n",
       "   'author_detail': {'name': 'Chunyan Miao'},\n",
       "   'author': 'Chunyan Miao',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2010.12284v2',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2010.12284v2',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.IR',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.IR',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': 'cs.LG',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]},\n",
       "  {'id': 'http://arxiv.org/abs/2101.02455v1',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2101.02455v1',\n",
       "   'updated': '2021-01-07T09:43:09Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=9, tm_min=43, tm_sec=9, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2021-01-07T09:43:09Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=9, tm_min=43, tm_sec=9, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'title': 'SuperMat: Construction of a linked annotated dataset from\\n  superconductors-related publications',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'SuperMat: Construction of a linked annotated dataset from\\n  superconductors-related publications'},\n",
       "   'summary': 'A growing number of papers are published in the area of superconducting\\nmaterials science. However, novel text and data mining (TDM) processes are\\nstill needed to efficiently access and exploit this accumulated knowledge,\\npaving the way towards data-driven materials design. Herein, we present\\nSuperMat (Superconductor Materials), an annotated corpus of linked data derived\\nfrom scientific publications on superconductors, which comprises 142 articles,\\n16052 entities, and 1398 links that are characterised into six categories: the\\nnames, classes, and properties of materials; links to their respective\\nsuperconducting critical temperature (Tc); and parametric conditions such as\\napplied pressure or measurement methods. The construction of SuperMat resulted\\nfrom a fruitful collaboration between computer scientists and material\\nscientists, and its high quality is ensured through validation by domain\\nexperts. The quality of the annotation guidelines was ensured by satisfactory\\nInter Annotator Agreement (IAA) between the annotators and the domain experts.\\nSuperMat includes the dataset, annotation guidelines, and annotation support\\ntools that use automatic suggestions to help minimise human errors.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'A growing number of papers are published in the area of superconducting\\nmaterials science. However, novel text and data mining (TDM) processes are\\nstill needed to efficiently access and exploit this accumulated knowledge,\\npaving the way towards data-driven materials design. Herein, we present\\nSuperMat (Superconductor Materials), an annotated corpus of linked data derived\\nfrom scientific publications on superconductors, which comprises 142 articles,\\n16052 entities, and 1398 links that are characterised into six categories: the\\nnames, classes, and properties of materials; links to their respective\\nsuperconducting critical temperature (Tc); and parametric conditions such as\\napplied pressure or measurement methods. The construction of SuperMat resulted\\nfrom a fruitful collaboration between computer scientists and material\\nscientists, and its high quality is ensured through validation by domain\\nexperts. The quality of the annotation guidelines was ensured by satisfactory\\nInter Annotator Agreement (IAA) between the annotators and the domain experts.\\nSuperMat includes the dataset, annotation guidelines, and annotation support\\ntools that use automatic suggestions to help minimise human errors.'},\n",
       "   'authors': [{'name': 'Luca Foppiano'},\n",
       "    {'name': 'Sae Dieb'},\n",
       "    {'name': 'Akira Suzuki'},\n",
       "    {'name': 'Pedro Baptista de Castro'},\n",
       "    {'name': 'Suguru Iwasaki'},\n",
       "    {'name': 'Azusa Uzuki'},\n",
       "    {'name': 'Miren Garbine Esparza Echevarria'},\n",
       "    {'name': 'Yan Meng'},\n",
       "    {'name': 'Kensei Terashima'},\n",
       "    {'name': 'Laurent Romary'},\n",
       "    {'name': 'Yoshihiko Takano'},\n",
       "    {'name': 'Masashi Ishii'}],\n",
       "   'author_detail': {'name': 'Masashi Ishii'},\n",
       "   'arxiv_affiliation': 'NIMS',\n",
       "   'author': 'Masashi Ishii',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2101.02455v1',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2101.02455v1',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cond-mat.supr-con',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cond-mat.supr-con',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]},\n",
       "  {'id': 'http://arxiv.org/abs/2011.05152v3',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2011.05152v3',\n",
       "   'updated': '2021-01-07T09:40:55Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=9, tm_min=40, tm_sec=55, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2020-11-10T15:19:01Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=10, tm_hour=15, tm_min=19, tm_sec=1, tm_wday=1, tm_yday=315, tm_isdst=0),\n",
       "   'title': 'Multi-Task Sequence Prediction For Tunisian Arabizi Multi-Level\\n  Annotation',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Multi-Task Sequence Prediction For Tunisian Arabizi Multi-Level\\n  Annotation'},\n",
       "   'summary': 'In this paper we propose a multi-task sequence prediction system, based on\\nrecurrent neural networks and used to annotate on multiple levels an Arabizi\\nTunisian corpus. The annotation performed are text classification,\\ntokenization, PoS tagging and encoding of Tunisian Arabizi into CODA* Arabic\\northography. The system is learned to predict all the annotation levels in\\ncascade, starting from Arabizi input. We evaluate the system on the TIGER\\nGerman corpus, suitably converting data to have a multi-task problem, in order\\nto show the effectiveness of our neural architecture. We show also how we used\\nthe system in order to annotate a Tunisian Arabizi corpus, which has been\\nafterwards manually corrected and used to further evaluate sequence models on\\nTunisian data. Our system is developed for the Fairseq framework, which allows\\nfor a fast and easy use for any other sequence prediction problem.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'In this paper we propose a multi-task sequence prediction system, based on\\nrecurrent neural networks and used to annotate on multiple levels an Arabizi\\nTunisian corpus. The annotation performed are text classification,\\ntokenization, PoS tagging and encoding of Tunisian Arabizi into CODA* Arabic\\northography. The system is learned to predict all the annotation levels in\\ncascade, starting from Arabizi input. We evaluate the system on the TIGER\\nGerman corpus, suitably converting data to have a multi-task problem, in order\\nto show the effectiveness of our neural architecture. We show also how we used\\nthe system in order to annotate a Tunisian Arabizi corpus, which has been\\nafterwards manually corrected and used to further evaluate sequence models on\\nTunisian data. Our system is developed for the Fairseq framework, which allows\\nfor a fast and easy use for any other sequence prediction problem.'},\n",
       "   'authors': [{'name': 'Elisa Gugliotta'},\n",
       "    {'name': 'Marco Dinarelli'},\n",
       "    {'name': 'Olivier Kraif'}],\n",
       "   'author_detail': {'name': 'Olivier Kraif'},\n",
       "   'arxiv_affiliation': 'Université Grenoble Alpes- Laboratoire LIDILEM',\n",
       "   'author': 'Olivier Kraif',\n",
       "   'arxiv_comment': 'Paper accepted at the Fifth Arabic Natural Language Processing\\n  Workshop (WANLP) 2020',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2011.05152v3',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2011.05152v3',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.CL',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.CL',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]},\n",
       "  {'id': 'http://arxiv.org/abs/2101.02046v2',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2101.02046v2',\n",
       "   'updated': '2021-01-07T09:28:10Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=9, tm_min=28, tm_sec=10, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2021-01-06T14:02:42Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=6, tm_hour=14, tm_min=2, tm_sec=42, tm_wday=2, tm_yday=6, tm_isdst=0),\n",
       "   'title': 'TextBox: A Unified, Modularized, and Extensible Framework for Text\\n  Generation',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'TextBox: A Unified, Modularized, and Extensible Framework for Text\\n  Generation'},\n",
       "   'summary': 'We release an open library, called TextBox, which provides a unified,\\nmodularized, and extensible text generation framework. TextBox aims to support\\na broad set of text generation tasks and models. In TextBox, we implements\\nseveral text generation models on benchmark datasets, covering the categories\\nof VAE, GAN, pre-trained language models, etc. Meanwhile, our library maintains\\nsufficient modularity and extensibility by properly decomposing the model\\narchitecture, inference, learning process into highly reusable modules, which\\nallows easily incorporating new models into our framework. It is specially\\nsuitable for researchers and practitioners to efficiently reproduce baseline\\nmodels and develop new models. TextBox is implemented based on PyTorch, and\\nreleased under Apache License 2.0 at https://github.com/RUCAIBox/TextBox.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'We release an open library, called TextBox, which provides a unified,\\nmodularized, and extensible text generation framework. TextBox aims to support\\na broad set of text generation tasks and models. In TextBox, we implements\\nseveral text generation models on benchmark datasets, covering the categories\\nof VAE, GAN, pre-trained language models, etc. Meanwhile, our library maintains\\nsufficient modularity and extensibility by properly decomposing the model\\narchitecture, inference, learning process into highly reusable modules, which\\nallows easily incorporating new models into our framework. It is specially\\nsuitable for researchers and practitioners to efficiently reproduce baseline\\nmodels and develop new models. TextBox is implemented based on PyTorch, and\\nreleased under Apache License 2.0 at https://github.com/RUCAIBox/TextBox.'},\n",
       "   'authors': [{'name': 'Junyi Li'},\n",
       "    {'name': 'Tianyi Tang'},\n",
       "    {'name': 'Gaole He'},\n",
       "    {'name': 'Jinhao Jiang'},\n",
       "    {'name': 'Xiaoxuan Hu'},\n",
       "    {'name': 'Puzhao Xie'},\n",
       "    {'name': 'Wayne Xin Zhao'},\n",
       "    {'name': 'Ji-Rong Wen'}],\n",
       "   'author_detail': {'name': 'Ji-Rong Wen'},\n",
       "   'author': 'Ji-Rong Wen',\n",
       "   'arxiv_comment': '9 pages, 2 figures, 4 tables. For our GitHub page, see\\n  https://github.com/RUCAIBox/TextBox',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2101.02046v2',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2101.02046v2',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.AI',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.AI',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]},\n",
       "  {'id': 'http://arxiv.org/abs/2101.01424v2',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2101.01424v2',\n",
       "   'updated': '2021-01-07T08:48:30Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=8, tm_min=48, tm_sec=30, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2021-01-05T09:27:26Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=5, tm_hour=9, tm_min=27, tm_sec=26, tm_wday=1, tm_yday=5, tm_isdst=0),\n",
       "   'title': 'Arithmetic quotients of the Bruhat-Tits building for projective general\\n  linear group in positive characteristic',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Arithmetic quotients of the Bruhat-Tits building for projective general\\n  linear group in positive characteristic'},\n",
       "   'summary': 'Let $d \\\\ge 1$. We study a subspace of the space of automorphic forms of\\n$\\\\mathrm{GL}_d$ over a global field of positive characteristic (or, a function\\nfield of a curve over a finite field). We fix a place $\\\\infty$ of $F$, and we\\nconsider the subspace $\\\\mathcal{A}_{\\\\mathrm{St}}$ consisting of automorphic\\nforms such that the local component at $\\\\infty$ of the associated automorphic\\nrepresentation is the Steinberg representation (to be made precise in the\\ntext).\\n  We have two results.\\n  One theorem (Theorem 16) describes the constituents of\\n$\\\\mathcal{A}_{\\\\mathrm{St}}$ as automorphic representation and gives a\\nmultiplicity one type statement.\\n  For the other theorem (Theorem 12), we construct, using the geometry of the\\nBruhat-Tits building, an analogue of modular symbols in\\n$\\\\mathcal{A}_{\\\\mathrm{St}}$ integrally (that is, in the space of\\n$\\\\mathbb{Z}$-valued automorphic forms). We show that the quotient is finite and\\ngive a bound on the exponent of this quotient.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Let $d \\\\ge 1$. We study a subspace of the space of automorphic forms of\\n$\\\\mathrm{GL}_d$ over a global field of positive characteristic (or, a function\\nfield of a curve over a finite field). We fix a place $\\\\infty$ of $F$, and we\\nconsider the subspace $\\\\mathcal{A}_{\\\\mathrm{St}}$ consisting of automorphic\\nforms such that the local component at $\\\\infty$ of the associated automorphic\\nrepresentation is the Steinberg representation (to be made precise in the\\ntext).\\n  We have two results.\\n  One theorem (Theorem 16) describes the constituents of\\n$\\\\mathcal{A}_{\\\\mathrm{St}}$ as automorphic representation and gives a\\nmultiplicity one type statement.\\n  For the other theorem (Theorem 12), we construct, using the geometry of the\\nBruhat-Tits building, an analogue of modular symbols in\\n$\\\\mathcal{A}_{\\\\mathrm{St}}$ integrally (that is, in the space of\\n$\\\\mathbb{Z}$-valued automorphic forms). We show that the quotient is finite and\\ngive a bound on the exponent of this quotient.'},\n",
       "   'authors': [{'name': 'Satoshi Kondo'}, {'name': 'Seidai Yasuda'}],\n",
       "   'author_detail': {'name': 'Seidai Yasuda'},\n",
       "   'author': 'Seidai Yasuda',\n",
       "   'arxiv_comment': 'arXiv admin note: substantial text overlap with arXiv:1406.7047',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2101.01424v2',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2101.01424v2',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'math.NT',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'math.NT',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': '11F67 11F70 (Primary) 20E42 (Secondary)',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]},\n",
       "  {'id': 'http://arxiv.org/abs/2101.02424v1',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2101.02424v1',\n",
       "   'updated': '2021-01-07T08:19:25Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=8, tm_min=19, tm_sec=25, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2021-01-07T08:19:25Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=8, tm_min=19, tm_sec=25, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'title': 'Detecting Suspicious Events in Fast Information Flows',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Detecting Suspicious Events in Fast Information Flows'},\n",
       "   'summary': \"We describe a computational feather-light and intuitive, yet provably\\nefficient algorithm, named HALFADO. HALFADO is designed for detecting\\nsuspicious events in a high-frequency stream of complex entries, based on a\\nrelatively small number of examples of human judgement. Operating a\\nsufficiently accurate detection system is vital for {\\\\em assisting} teams of\\nhuman experts in many different areas of the modern digital society. These\\nsystems have intrinsically a far-reaching normative effect, and public\\nknowledge of the workings of such technology should be a human right.\\n  On a conceptual level, the present approach extends one of the most classical\\nlearning algorithms for classification, inheriting its theoretical properties.\\nIt however works in a semi-supervised way integrating human and computational\\nintelligence. On a practical level, this algorithm transcends existing\\napproaches (expert systems) by managing and boosting their performance into a\\nsingle global detector.\\n  We illustrate HALFADO's efficacy on two challenging applications: (1) for\\ndetecting {\\\\em hate speech} messages in a flow of text messages gathered from a\\nsocial media platform, and (2) for a Transaction Monitoring System (TMS) in\\nFinTech detecting fraudulent transactions in a stream of financial\\ntransactions.\\n  This algorithm illustrates that - contrary to popular belief - advanced\\nmethods of machine learning need not require neither advanced levels of\\ncomputation power nor expensive annotation efforts.\",\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"We describe a computational feather-light and intuitive, yet provably\\nefficient algorithm, named HALFADO. HALFADO is designed for detecting\\nsuspicious events in a high-frequency stream of complex entries, based on a\\nrelatively small number of examples of human judgement. Operating a\\nsufficiently accurate detection system is vital for {\\\\em assisting} teams of\\nhuman experts in many different areas of the modern digital society. These\\nsystems have intrinsically a far-reaching normative effect, and public\\nknowledge of the workings of such technology should be a human right.\\n  On a conceptual level, the present approach extends one of the most classical\\nlearning algorithms for classification, inheriting its theoretical properties.\\nIt however works in a semi-supervised way integrating human and computational\\nintelligence. On a practical level, this algorithm transcends existing\\napproaches (expert systems) by managing and boosting their performance into a\\nsingle global detector.\\n  We illustrate HALFADO's efficacy on two challenging applications: (1) for\\ndetecting {\\\\em hate speech} messages in a flow of text messages gathered from a\\nsocial media platform, and (2) for a Transaction Monitoring System (TMS) in\\nFinTech detecting fraudulent transactions in a stream of financial\\ntransactions.\\n  This algorithm illustrates that - contrary to popular belief - advanced\\nmethods of machine learning need not require neither advanced levels of\\ncomputation power nor expensive annotation efforts.\"},\n",
       "   'authors': [{'name': 'Kristiaan Pelckmans'},\n",
       "    {'name': 'Moustafa Aboushady'},\n",
       "    {'name': 'Andreas Brosemyr'}],\n",
       "   'author_detail': {'name': 'Andreas Brosemyr'},\n",
       "   'author': 'Andreas Brosemyr',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2101.02424v1',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2101.02424v1',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.LG',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': 'cs.AI',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]},\n",
       "  {'id': 'http://arxiv.org/abs/2101.02394v1',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2101.02394v1',\n",
       "   'updated': '2021-01-07T06:17:15Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=6, tm_min=17, tm_sec=15, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2021-01-07T06:17:15Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=6, tm_min=17, tm_sec=15, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'title': 'Read, Retrospect, Select: An MRC Framework to Short Text Entity Linking',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Read, Retrospect, Select: An MRC Framework to Short Text Entity Linking'},\n",
       "   'summary': 'Entity linking (EL) for the rapidly growing short text (e.g. search queries\\nand news titles) is critical to industrial applications. Most existing\\napproaches relying on adequate context for long text EL are not effective for\\nthe concise and sparse short text. In this paper, we propose a novel framework\\ncalled Multi-turn Multiple-choice Machine reading comprehension (M3}) to solve\\nthe short text EL from a new perspective: a query is generated for each\\nambiguous mention exploiting its surrounding context, and an option selection\\nmodule is employed to identify the golden entity from candidates using the\\nquery. In this way, M3 framework sufficiently interacts limited context with\\ncandidate entities during the encoding process, as well as implicitly considers\\nthe dissimilarities inside the candidate bunch in the selection stage. In\\naddition, we design a two-stage verifier incorporated into M3 to address the\\ncommonly existed unlinkable problem in short text. To further consider the\\ntopical coherence and interdependence among referred entities, M3 leverages a\\nmulti-turn fashion to deal with mentions in a sequence manner by retrospecting\\nhistorical cues. Evaluation shows that our M3 framework achieves the\\nstate-of-the-art performance on five Chinese and English datasets for the\\nreal-world short text EL.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Entity linking (EL) for the rapidly growing short text (e.g. search queries\\nand news titles) is critical to industrial applications. Most existing\\napproaches relying on adequate context for long text EL are not effective for\\nthe concise and sparse short text. In this paper, we propose a novel framework\\ncalled Multi-turn Multiple-choice Machine reading comprehension (M3}) to solve\\nthe short text EL from a new perspective: a query is generated for each\\nambiguous mention exploiting its surrounding context, and an option selection\\nmodule is employed to identify the golden entity from candidates using the\\nquery. In this way, M3 framework sufficiently interacts limited context with\\ncandidate entities during the encoding process, as well as implicitly considers\\nthe dissimilarities inside the candidate bunch in the selection stage. In\\naddition, we design a two-stage verifier incorporated into M3 to address the\\ncommonly existed unlinkable problem in short text. To further consider the\\ntopical coherence and interdependence among referred entities, M3 leverages a\\nmulti-turn fashion to deal with mentions in a sequence manner by retrospecting\\nhistorical cues. Evaluation shows that our M3 framework achieves the\\nstate-of-the-art performance on five Chinese and English datasets for the\\nreal-world short text EL.'},\n",
       "   'authors': [{'name': 'Yingjie Gu'},\n",
       "    {'name': 'Xiaoye Qu'},\n",
       "    {'name': 'Zhefeng Wang'},\n",
       "    {'name': 'Baoxing Huai'},\n",
       "    {'name': 'Nicholas Jing Yuan'},\n",
       "    {'name': 'Xiaolin Gui'}],\n",
       "   'author_detail': {'name': 'Xiaolin Gui'},\n",
       "   'author': 'Xiaolin Gui',\n",
       "   'arxiv_comment': 'Accepted at AAAI 2021',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2101.02394v1',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2101.02394v1',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.CL',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.CL',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]},\n",
       "  {'id': 'http://arxiv.org/abs/2012.13915v2',\n",
       "   'guidislink': True,\n",
       "   'link': 'http://arxiv.org/abs/2012.13915v2',\n",
       "   'updated': '2021-01-07T05:48:45Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=7, tm_hour=5, tm_min=48, tm_sec=45, tm_wday=3, tm_yday=7, tm_isdst=0),\n",
       "   'published': '2020-12-27T11:09:35Z',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=27, tm_hour=11, tm_min=9, tm_sec=35, tm_wday=6, tm_yday=362, tm_isdst=0),\n",
       "   'title': 'SG-Net: Syntax Guided Transformer for Language Representation',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'SG-Net: Syntax Guided Transformer for Language Representation'},\n",
       "   'summary': 'Understanding human language is one of the key themes of artificial\\nintelligence. For language representation, the capacity of effectively modeling\\nthe linguistic knowledge from the detail-riddled and lengthy texts and getting\\nrid of the noises is essential to improve its performance. Traditional\\nattentive models attend to all words without explicit constraint, which results\\nin inaccurate concentration on some dispensable words. In this work, we propose\\nusing syntax to guide the text modeling by incorporating explicit syntactic\\nconstraints into attention mechanisms for better linguistically motivated word\\nrepresentations. In detail, for self-attention network (SAN) sponsored\\nTransformer-based encoder, we introduce syntactic dependency of interest (SDOI)\\ndesign into the SAN to form an SDOI-SAN with syntax-guided self-attention.\\nSyntax-guided network (SG-Net) is then composed of this extra SDOI-SAN and the\\nSAN from the original Transformer encoder through a dual contextual\\narchitecture for better linguistics inspired representation. The proposed\\nSG-Net is applied to typical Transformer encoders. Extensive experiments on\\npopular benchmark tasks, including machine reading comprehension, natural\\nlanguage inference, and neural machine translation show the effectiveness of\\nthe proposed SG-Net design.',\n",
       "   'summary_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Understanding human language is one of the key themes of artificial\\nintelligence. For language representation, the capacity of effectively modeling\\nthe linguistic knowledge from the detail-riddled and lengthy texts and getting\\nrid of the noises is essential to improve its performance. Traditional\\nattentive models attend to all words without explicit constraint, which results\\nin inaccurate concentration on some dispensable words. In this work, we propose\\nusing syntax to guide the text modeling by incorporating explicit syntactic\\nconstraints into attention mechanisms for better linguistically motivated word\\nrepresentations. In detail, for self-attention network (SAN) sponsored\\nTransformer-based encoder, we introduce syntactic dependency of interest (SDOI)\\ndesign into the SAN to form an SDOI-SAN with syntax-guided self-attention.\\nSyntax-guided network (SG-Net) is then composed of this extra SDOI-SAN and the\\nSAN from the original Transformer encoder through a dual contextual\\narchitecture for better linguistics inspired representation. The proposed\\nSG-Net is applied to typical Transformer encoders. Extensive experiments on\\npopular benchmark tasks, including machine reading comprehension, natural\\nlanguage inference, and neural machine translation show the effectiveness of\\nthe proposed SG-Net design.'},\n",
       "   'authors': [{'name': 'Zhuosheng Zhang'},\n",
       "    {'name': 'Yuwei Wu'},\n",
       "    {'name': 'Junru Zhou'},\n",
       "    {'name': 'Sufeng Duan'},\n",
       "    {'name': 'Hai Zhao'},\n",
       "    {'name': 'Rui Wang'}],\n",
       "   'author_detail': {'name': 'Rui Wang'},\n",
       "   'author': 'Rui Wang',\n",
       "   'arxiv_comment': 'The early version accepted by IEEE Transactions on Pattern Analysis\\n  and Machine Intelligence (TPAMI). Journal extension of arXiv:1908.05147 (AAAI\\n  2020)',\n",
       "   'links': [{'href': 'http://arxiv.org/abs/2012.13915v2',\n",
       "     'rel': 'alternate',\n",
       "     'type': 'text/html'},\n",
       "    {'title': 'pdf',\n",
       "     'href': 'http://arxiv.org/pdf/2012.13915v2',\n",
       "     'rel': 'related',\n",
       "     'type': 'application/pdf'}],\n",
       "   'arxiv_primary_category': {'term': 'cs.CL',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "   'tags': [{'term': 'cs.CL',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': 'cs.AI',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None},\n",
       "    {'term': 'cs.IR',\n",
       "     'scheme': 'http://arxiv.org/schemas/atom',\n",
       "     'label': None}]}],\n",
       " 'feed': {'links': [{'href': 'http://arxiv.org/api/query?search_query%3Dabs%3Atext%20generationANDabs%3Anarrative%26id_list%3D%26start%3D0%26max_results%3D10',\n",
       "    'rel': 'self',\n",
       "    'type': 'application/atom+xml'}],\n",
       "  'title': 'ArXiv Query: search_query=abs:text generationANDabs:narrative&amp;id_list=&amp;start=0&amp;max_results=10',\n",
       "  'title_detail': {'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'ArXiv Query: search_query=abs:text generationANDabs:narrative&amp;id_list=&amp;start=0&amp;max_results=10'},\n",
       "  'id': 'http://arxiv.org/api/2ej4k1ml3BL2tGzEneo5tfxMvJY',\n",
       "  'guidislink': True,\n",
       "  'link': 'http://arxiv.org/api/2ej4k1ml3BL2tGzEneo5tfxMvJY',\n",
       "  'updated': '2021-01-08T00:00:00-05:00',\n",
       "  'updated_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=8, tm_hour=5, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=8, tm_isdst=0),\n",
       "  'opensearch_totalresults': '14490',\n",
       "  'opensearch_startindex': '0',\n",
       "  'opensearch_itemsperpage': '10'},\n",
       " 'headers': {},\n",
       " 'encoding': 'utf-8',\n",
       " 'version': 'atom10',\n",
       " 'namespaces': {'': 'http://www.w3.org/2005/Atom',\n",
       "  'opensearch': 'http://a9.com/-/spec/opensearch/1.1/',\n",
       "  'arxiv': 'http://arxiv.org/schemas/atom'}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=text+generation&terms-0-field=abstract&terms-1-operator=AND&terms-1-term=narrative+generation&terms-1-field=abstract&terms-2-operator=OR&terms-2-term=story&terms-2-field=title&classification-computer_science=y&classification-physics_archives=all&classification-include_cross_list=include&date-filter_by=all_dates&date-year=&date-from_date=&date-to_date=&date-date_type=submitted_date_first&abstracts=hide&size=50&order=-announced_date_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url + query)\n",
    "feed = atoma.parse_atom_bytes(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "arts2 = {}\n",
    "\n",
    "cats_of_interest = ['cs.CL', 'cs.HC', 'cs.AI', 'cs.DL', 'cs.GT', 'cs.GL', 'cs.IR', 'cs.DB',\n",
    "                               'cs.IT', 'cs.LG', 'cs.MA', 'cs.MM', 'cs.NE', 'cs.SI']\n",
    "queries = {\"story\": search_query_story, \n",
    "           \"table2text\": search_query_tables, \n",
    "           \"games\": search_query_games, \n",
    "           \"dialogue\": search_query_dialogue, \n",
    "           \"knowledge\": search_query_knowledge, \n",
    "           \"poetry\": search_query_poetry, \n",
    "           \"image2text\": search_query_images}\n",
    "\n",
    "sort = \"&sortBy=lastUpdatedDate&sortOrder=descending\"\n",
    "start = 0                     # retreive the first 150 results\n",
    "max_results = 200\n",
    "\n",
    "for searchtype, querystring in queries.items():\n",
    "    query = 'search_query=%s&start=%i&max_results=%i' % (querystring,\n",
    "                                                     start,\n",
    "                                                     max_results) + sort\n",
    "    response = requests.get(base_url + query)\n",
    "    feed = atoma.parse_atom_bytes(response.content)\n",
    "    arts2[searchtype] = []\n",
    "    for entry in feed.entries:\n",
    "        cats = []\n",
    "        for cat in entry.categories:\n",
    "            cats.append(cat.term)\n",
    "        if not set(cats).intersection(set(cats_of_interest)):\n",
    "            continue\n",
    "        pubdate = entry.published\n",
    "        title = entry.title.value\n",
    "        authors = []\n",
    "        for author in entry.authors:\n",
    "            authors.append(author.name)\n",
    "        abslink = entry.id_\n",
    "        text = entry.summary.value\n",
    "        data = {'title': title, 'pubdate': pubdate, 'id': abslink, \n",
    "                'authors': ', '.join(authors), 'categories': ', '.join(cats),\n",
    "               'search': searchtype, 'abstract': text}\n",
    "        arts2[searchtype].append(data)\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['story', 'table2text', 'games', 'dialogue', 'knowledge', 'poetry', 'image2text'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arts2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "arts3 = dict(zip(queries.keys(), arts2.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['story', 'tables', 'games', 'dialogue', 'knowledge', 'poetry', 'image2text'])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arts3.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story 33\n",
      "table2text 194\n",
      "games 13\n",
      "dialogue 1\n",
      "knowledge 194\n",
      "poetry 12\n",
      "image2text 108\n"
     ]
    }
   ],
   "source": [
    "for key, val in arts2.items():\n",
    "    print(key, len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "for x in more_itertools.chunked(arts2['knowledge'], 100):\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the csv data files\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_df_from_new_vals(vals):\n",
    "    # scraped new data\n",
    "    df = pd.DataFrame(vals)\n",
    "    df['pubdate'] = pd.to_datetime(df['pubdate'])\n",
    "    df.sort_values(by=[\"pubdate\", \"title\"], ascending=False)\n",
    "    df['displaydate'] = df['pubdate'].dt.strftime('%Y-%m-%d')\n",
    "    return df\n",
    "\n",
    "def read_data_csv(filename):\n",
    "    # read old data files\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "def read_data_csv_date(date, categ):\n",
    "    path = Path(f\"_data/{categ}/\").glob(f\"{date}-{categ}-*.csv\")\n",
    "    file = [str(x) for x in path][0]\n",
    "    df = pd.read_csv(file)\n",
    "    df.sort_values(by=\"pubdate\", ascending=False)\n",
    "    return df\n",
    "\n",
    "def write_data_file(vals, key, tag=None, columns=['title','pubdate','id','authors','categories','search','abstract','displaydate']):\n",
    "    # writes a dataframe with today's date or top date - assumes already created cols\n",
    "    df = pd.DataFrame(vals, columns=columns)\n",
    "    df.sort_values(by=\"pubdate\", inplace=True, ascending=False)  # fix sort order for display\n",
    "    date = df.iloc[0]['displaydate']  # if it's a full list, use the top of the list as date\n",
    "    print(\"writing new file\", date)\n",
    "    if tag:\n",
    "        df.to_csv(f'_data/{key}/{tag}-' + date + '-' + key + '-' + str(len(df)) + '.csv', index=None)\n",
    "    else:\n",
    "        df.to_csv(f'_data/{key}/' + date + '-' + key + '-' + str(len(df)) + '.csv', index=None)\n",
    "    return date\n",
    "\n",
    "def merge_with_previous(category, newdata):\n",
    "    most_recent = get_latest_datafile(category)\n",
    "    date, cat, count = parse_filename(most_recent)\n",
    "    newdf = create_df_from_new_vals(newdata)\n",
    "    df = pd.read_csv(most_recent)\n",
    "    if int(count) < 100:\n",
    "        newdf = pd.concat([newdf, df]).drop_duplicates(subset=\"id\")  # should we then delete the last most recent?\n",
    "        newdf.sort_values(by=\"pubdate\", inplace=True, ascending=False)\n",
    "    # else what? also what about len(new)\n",
    "    if len(df) == len(newdf):\n",
    "        return [], None\n",
    "    else:\n",
    "        return newdf, date  # date of most recent, to delete\n",
    "    \n",
    "def write_new_data(categ, newdata):\n",
    "    # newdata is list of values not yet a df\n",
    "    # use the crawled new data and join it with old data files\n",
    "    newdf, prevdate = merge_with_previous(categ, newdata)  # newdf is sorted\n",
    "    # use date to remove the .md file of that date\n",
    "    newfiledates = []\n",
    "    if len(newdf):\n",
    "        newdf.sort_values(by='pubdate', ascending=True)\n",
    "        newdfdata = newdf.values.tolist()\n",
    "        columns = newdf.columns\n",
    "        if len(newdata) > 120:\n",
    "            for x in more_itertools.chunked(newdfdata, 60):\n",
    "                new = write_data_file(x, categ, columns=columns, tag=None)\n",
    "                newfiledates.append(new)\n",
    "        else:\n",
    "            new = write_data_file(newdfdata, categ, columns=columns, tag=None)\n",
    "            newfiledates.append(new)\n",
    "    else:\n",
    "        print(\"no new data to write\")\n",
    "    return newfiledates, prevdate\n",
    "\n",
    "def write_all_data_files(categ, df, tag=None):\n",
    "    # just for cleanup, dont use in prod\n",
    "    columns = df.columns\n",
    "    df.sort_values(by=\"pubdate\", ascending=True, inplace=True)  # you want the old ones written first as 100's\n",
    "    if len(df) > 100:\n",
    "        for x in more_itertools.chunked(df.values.tolist(), 100):\n",
    "            write_data_file(x, categ, tag=tag, columns=columns)\n",
    "    else:\n",
    "        write_data_file(df.values.tolist(), categ, tag=tag, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arts2['story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Political Depolarization of News Articles Using Attribute-aware Word\\n  Embeddings',\n",
       "  'pubdate': datetime.datetime(2021, 1, 5, 7, 39, 12, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2101.01391v1',\n",
       "  'authors': 'Ruibo Liu, Lili Wang, Chenyan Jia, Soroush Vosoughi',\n",
       "  'categories': 'cs.CL, cs.AI',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Political polarization in the US is on the rise. This polarization negatively\\naffects the public sphere by contributing to the creation of ideological echo\\nchambers. In this paper, we focus on addressing one of the factors that\\ncontributes to this polarity, polarized media. We introduce a framework for\\ndepolarizing news articles. Given an article on a certain topic with a\\nparticular ideological slant (eg., liberal or conservative), the framework\\nfirst detects polar language in the article and then generates a new article\\nwith the polar language replaced with neutral expressions. To detect polar\\nwords, we train a multi-attribute-aware word embedding model that is aware of\\nideology and topics on 360k full-length media articles. Then, for text\\ngeneration, we propose a new algorithm called Text Annealing Depolarization\\nAlgorithm (TADA). TADA retrieves neutral expressions from the word embedding\\nmodel that not only decrease ideological polarity but also preserve the\\noriginal argument of the text, while maintaining grammatical correctness. We\\nevaluate our framework by comparing the depolarized output of our model in two\\nmodes, fully-automatic and semi-automatic, on 99 stories spanning 11 topics.\\nBased on feedback from 161 human testers, our framework successfully\\ndepolarized 90.1% of paragraphs in semi-automatic mode and 78.3% of paragraphs\\nin fully-automatic mode. Furthermore, 81.2% of the testers agree that the\\nnon-polar content information is well-preserved and 79% agree that\\ndepolarization does not harm semantic correctness when they compare the\\noriginal text and the depolarized text. Our work shows that data-driven methods\\ncan help to locate political polarity and aid in the depolarization of\\narticles.'},\n",
       " {'title': 'Outline to Story: Fine-grained Controllable Story Generation from\\n  Cascaded Events',\n",
       "  'pubdate': datetime.datetime(2021, 1, 4, 8, 16, 21, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2101.00822v1',\n",
       "  'authors': 'Le Fang, Tao Zeng, Chaochun Liu, Liefeng Bo, Wen Dong, Changyou Chen',\n",
       "  'categories': 'cs.CL, cs.AI, cs.LG',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Large-scale pretrained language models have shown thrilling generation\\ncapabilities, especially when they generate consistent long text in thousands\\nof words with ease. However, users of these models can only control the prefix\\nof sentences or certain global aspects of generated text. It is challenging to\\nsimultaneously achieve fine-grained controllability and preserve the\\nstate-of-the-art unconditional text generation capability. In this paper, we\\nfirst propose a new task named \"Outline to Story\" (O2S) as a test bed for\\nfine-grained controllable generation of long text, which generates a\\nmulti-paragraph story from cascaded events, i.e. a sequence of outline events\\nthat guide subsequent paragraph generation. We then create dedicate datasets\\nfor future benchmarks, built by state-of-the-art keyword extraction techniques.\\nFinally, we propose an extremely simple yet strong baseline method for the O2S\\ntask, which fine tunes pre-trained language models on augmented sequences of\\noutline-story pairs with simple language modeling objective. Our method does\\nnot introduce any new parameters or perform any architecture modification,\\nexcept several special tokens as delimiters to build augmented sequences.\\nExtensive experiments on various datasets demonstrate state-of-the-art\\nconditional story generation performance with our model, achieving better\\nfine-grained controllability and user flexibility. Our paper is among the first\\nones by our knowledge to propose a model and to create datasets for the task of\\n\"outline to story\". Our work also instantiates research interest of\\nfine-grained controllable generation of open-domain long text, where\\ncontrolling inputs are represented by short text.'},\n",
       " {'title': 'Facts2Story: Controlling Text Generation by Key Facts',\n",
       "  'pubdate': datetime.datetime(2020, 12, 8, 10, 14, 29, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2012.04332v1',\n",
       "  'authors': 'Eyal Orbach, Yoav Goldberg',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Recent advancements in self-attention neural network architectures have\\nraised the bar for open-ended text generation. Yet, while current methods are\\ncapable of producing a coherent text which is several hundred words long,\\nattaining control over the content that is being generated -- as well as\\nevaluating it -- are still open questions. We propose a controlled generation\\ntask which is based on expanding a sequence of facts, expressed in natural\\nlanguage, into a longer narrative. We introduce human-based evaluation metrics\\nfor this task, as well as a method for deriving a large training dataset. We\\nevaluate three methods on this task, based on fine-tuning pre-trained models.\\nWe show that while auto-regressive, unidirectional Language Models such as GPT2\\nproduce better fluency, they struggle to adhere to the requested facts. We\\npropose a plan-and-cloze model (using fine-tuned XLNet) which produces\\ncompetitive fluency while adhering to the requested content.'},\n",
       " {'title': 'Back to the Future: Unsupervised Backprop-based Decoding for\\n  Counterfactual and Abductive Commonsense Reasoning',\n",
       "  'pubdate': datetime.datetime(2020, 10, 12, 17, 58, 43, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2010.05906v3',\n",
       "  'authors': 'Lianhui Qin, Vered Shwartz, Peter West, Chandra Bhagavatula, Jena Hwang, Ronan Le Bras, Antoine Bosselut, Yejin Choi',\n",
       "  'categories': 'cs.CL, cs.AI, cs.LG',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Abductive and counterfactual reasoning, core abilities of everyday human\\ncognition, require reasoning about what might have happened at time t, while\\nconditioning on multiple contexts from the relative past and future. However,\\nsimultaneous incorporation of past and future contexts using generative\\nlanguage models (LMs) can be challenging, as they are trained either to\\ncondition only on the past context or to perform narrowly scoped\\ntext-infilling. In this paper, we propose DeLorean, a new unsupervised decoding\\nalgorithm that can flexibly incorporate both the past and future contexts using\\nonly off-the-shelf, left-to-right language models and no supervision. The key\\nintuition of our algorithm is incorporating the future through\\nback-propagation, during which, we only update the internal representation of\\nthe output while fixing the model parameters. By alternating between forward\\nand backward propagation, DeLorean can decode the output representation that\\nreflects both the left and right contexts. We demonstrate that our approach is\\ngeneral and applicable to two nonmonotonic reasoning tasks: abductive text\\ngeneration and counterfactual story revision, where DeLorean outperforms a\\nrange of unsupervised and some supervised methods, based on automatic and human\\nevaluation.'},\n",
       " {'title': 'Machine Generation and Detection of Arabic Manipulated and Fake News',\n",
       "  'pubdate': datetime.datetime(2020, 11, 5, 20, 50, 22, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2011.03092v1',\n",
       "  'authors': 'El Moatez Billah Nagoudi, AbdelRahim Elmadany, Muhammad Abdul-Mageed, Tariq Alhindi, Hasan Cavusoglu',\n",
       "  'categories': 'cs.CL, cs.LG',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Fake news and deceptive machine-generated text are serious problems\\nthreatening modern societies, including in the Arab world. This motivates work\\non detecting false and manipulated stories online. However, a bottleneck for\\nthis research is lack of sufficient data to train detection models. We present\\na novel method for automatically generating Arabic manipulated (and potentially\\nfake) news stories. Our method is simple and only depends on availability of\\ntrue stories, which are abundant online, and a part of speech tagger (POS). To\\nfacilitate future work, we dispense with both of these requirements altogether\\nby providing AraNews, a novel and large POS-tagged news dataset that can be\\nused off-the-shelf. Using stories generated based on AraNews, we carry out a\\nhuman annotation study that casts light on the effects of machine manipulation\\non text veracity. The study also measures human ability to detect Arabic\\nmachine manipulated text generated by our method. Finally, we develop the first\\nmodels for detecting manipulated Arabic news and achieve state-of-the-art\\nresults on Arabic fake news detection (macro F1=70.06). Our models and data are\\npublicly available.'},\n",
       " {'title': 'Dissecting the components and factors of Neural Text Generation',\n",
       "  'pubdate': datetime.datetime(2020, 10, 14, 17, 54, 42, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2010.07279v1',\n",
       "  'authors': 'Khyathi Raghavi Chandu, Alan W Black',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Neural text generation metamorphosed into several critical natural language\\napplications ranging from text completion to free form narrative generation.\\nGenerating natural language has fundamentally been a human attribute and the\\nadvent of ubiquitous NLP applications and virtual agents marks the need to\\nimpart this skill to machines. There has been a colossal research effort in\\nvarious frontiers of neural text generation including machine translation,\\nsummarization, image captioning, storytelling etc., We believe that this is an\\nexcellent juncture to retrospect on the directions of the field. Specifically,\\nthis paper surveys the fundamental factors and components relaying task\\nagnostic impacts across various generation tasks such as storytelling,\\nsummarization, translation etc., In specific, we present an abstraction of the\\nimperative techniques with respect to learning paradigms, pretraining, modeling\\napproaches, decoding and the key challenges. Thereby, we hope to deliver a\\none-stop destination for researchers in the field to facilitate a perspective\\non where to situate their work and how it impacts other closely related tasks.'},\n",
       " {'title': 'Content Planning for Neural Story Generation with Aristotelian Rescoring',\n",
       "  'pubdate': datetime.datetime(2020, 9, 21, 13, 41, 32, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2009.09870v2',\n",
       "  'authors': 'Seraphina Goldfarb-Tarrant, Tuhin Chakrabarty, Ralph Weischedel, Nanyun Peng',\n",
       "  'categories': 'cs.CL, cs.AI',\n",
       "  'search': 'story',\n",
       "  'abstract': \"Long-form narrative text generated from large language models manages a\\nfluent impersonation of human writing, but only at the local sentence level,\\nand lacks structure or global cohesion. We posit that many of the problems of\\nstory generation can be addressed via high-quality content planning, and\\npresent a system that focuses on how to learn good plot structures to guide\\nstory generation. We utilize a plot-generation language model along with an\\nensemble of rescoring models that each implement an aspect of good\\nstory-writing as detailed in Aristotle's Poetics. We find that stories written\\nwith our more principled plot-structure are both more relevant to a given\\nprompt and higher quality than baselines that do not content plan, or that plan\\nin an unprincipled way.\"},\n",
       " {'title': 'Sparse Text Generation',\n",
       "  'pubdate': datetime.datetime(2020, 4, 6, 13, 9, 10, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2004.02644v3',\n",
       "  'authors': 'Pedro Henrique Martins, Zita Marinho, André F. T. Martins',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Current state-of-the-art text generators build on powerful language models\\nsuch as GPT-2, achieving impressive performance. However, to avoid degenerate\\ntext, they require sampling from a modified softmax, via temperature parameters\\nor ad-hoc truncation techniques, as in top-$k$ or nucleus sampling. This\\ncreates a mismatch between training and testing conditions. In this paper, we\\nuse the recently introduced entmax transformation to train and sample from a\\nnatively sparse language model, avoiding this mismatch. The result is a text\\ngenerator with favorable performance in terms of fluency and consistency, fewer\\nrepetitions, and n-gram diversity closer to human text. In order to evaluate\\nour model, we propose three new metrics for comparing sparse or truncated\\ndistributions: $\\\\epsilon$-perplexity, sparsemax score, and Jensen-Shannon\\ndivergence. Human-evaluated experiments in story completion and dialogue\\ngeneration show that entmax sampling leads to more engaging and coherent\\nstories and conversations.'},\n",
       " {'title': 'MEGATRON-CNTRL: Controllable Story Generation with External Knowledge\\n  Using Large-Scale Language Models',\n",
       "  'pubdate': datetime.datetime(2020, 10, 2, 8, 7, 12, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2010.00840v1',\n",
       "  'authors': 'Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Raul Puri, Pascale Fung, Anima Anandkumar, Bryan Catanzaro',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Existing pre-trained large language models have shown unparalleled generative\\ncapabilities. However, they are not controllable. In this paper, we propose\\nMEGATRON-CNTRL, a novel framework that uses large-scale language models and\\nadds control to text generation by incorporating an external knowledge base.\\nOur framework consists of a keyword predictor, a knowledge retriever, a\\ncontextual knowledge ranker, and a conditional text generator. As we do not\\nhave access to ground-truth supervision for the knowledge ranker, we make use\\nof weak supervision from sentence embedding. The empirical results show that\\nour model generates more fluent, consistent, and coherent stories with less\\nrepetition and higher diversity compared to prior work on the ROC story\\ndataset. We showcase the controllability of our model by replacing the keywords\\nused to generate stories and re-running the generation process. Human\\nevaluation results show that 77.5% of these stories are successfully controlled\\nby the new keywords. Furthermore, by scaling our model from 124 million to 8.3\\nbillion parameters we demonstrate that larger models improve both the quality\\nof generation (from 74.5% to 93.0% for consistency) and controllability (from\\n77.5% to 91.5%).'},\n",
       " {'title': 'Navigating Human Language Models with Synthetic Agents',\n",
       "  'pubdate': datetime.datetime(2020, 8, 10, 14, 39, 53, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2008.04162v7',\n",
       "  'authors': 'Philip Feldman, Antonio Bucchiarone',\n",
       "  'categories': 'cs.AI, cs.CL, cs.MA, I.2; I.6; J.4',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Modern natural language models such as the GPT-2/GPT-3 contain tremendous\\namounts of information about human belief in a consistently testable form. If\\nthese models could be shown to accurately reflect the underlying beliefs of the\\nhuman beings that produced the data used to train these models, then such\\nmodels become a powerful sociological tool in ways that are distinct from\\ntraditional methods, such as interviews and surveys. In this study, We train a\\nversion of the GPT-2 on a corpora of historical chess games, and then \"launch\"\\nclusters of synthetic agents into the model, using text strings to create\\ncontext and orientation. We compare the trajectories contained in the text\\ngenerated by the agents/model and compare that to the known ground truth of the\\nchess board, move legality, and historical patterns of play. We find that the\\npercentages of moves by piece using the model are substantially similar from\\nhuman patterns. We further find that the model creates an accurate latent\\nrepresentation of the chessboard, and that it is possible to plot trajectories\\nof legal moves across the board using this knowledge.'},\n",
       " {'title': 'Graph-based Multi-hop Reasoning for Long Text Generation',\n",
       "  'pubdate': datetime.datetime(2020, 9, 28, 12, 47, 59, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2009.13282v1',\n",
       "  'authors': 'Liang Zhao, Jingjing Xu, Junyang Lin, Yichang Zhang, Hongxia Yang, Xu Sun',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Long text generation is an important but challenging task.The main problem\\nlies in learning sentence-level semantic dependencies which traditional\\ngenerative models often suffer from. To address this problem, we propose a\\nMulti-hop Reasoning Generation (MRG) approach that incorporates multi-hop\\nreasoning over a knowledge graph to learn semantic dependencies among\\nsentences. MRG consists of twoparts, a graph-based multi-hop reasoning module\\nand a path-aware sentence realization module. The reasoning module is\\nresponsible for searching skeleton paths from a knowledge graph to imitate the\\nimagination process in the human writing for semantic transfer. Based on the\\ninferred paths, the sentence realization module then generates a complete\\nsentence. Unlike previous black-box models, MRG explicitly infers the skeleton\\npath, which provides explanatory views tounderstand how the proposed model\\nworks. We conduct experiments on three representative tasks, including story\\ngeneration, review generation, and product description generation. Automatic\\nand manual evaluation show that our proposed method can generate more\\ninformative and coherentlong text than strong baselines, such as pre-trained\\nmodels(e.g. GPT-2) and knowledge-enhanced models.'},\n",
       " {'title': 'UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation',\n",
       "  'pubdate': datetime.datetime(2020, 9, 16, 11, 1, 46, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2009.07602v1',\n",
       "  'authors': 'Jian Guan, Minlie Huang',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Despite the success of existing referenced metrics (e.g., BLEU and\\nMoverScore), they correlate poorly with human judgments for open-ended text\\ngeneration including story or dialog generation because of the notorious\\none-to-many issue: there are many plausible outputs for the same input, which\\nmay differ substantially in literal or semantics from the limited number of\\ngiven references. To alleviate this issue, we propose UNION, a learnable\\nunreferenced metric for evaluating open-ended story generation, which measures\\nthe quality of a generated story without any reference. Built on top of BERT,\\nUNION is trained to distinguish human-written stories from negative samples and\\nrecover the perturbation in negative stories. We propose an approach of\\nconstructing negative samples by mimicking the errors commonly observed in\\nexisting NLG models, including repeated plots, conflicting logic, and\\nlong-range incoherence. Experiments on two story datasets demonstrate that\\nUNION is a reliable measure for evaluating the quality of generated stories,\\nwhich correlates better with human judgments and is more generalizable than\\nexisting state-of-the-art metrics.'},\n",
       " {'title': 'A Comparison of LSTM and BERT for Small Corpus',\n",
       "  'pubdate': datetime.datetime(2020, 9, 11, 14, 1, 14, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2009.05451v1',\n",
       "  'authors': 'Aysu Ezen-Can',\n",
       "  'categories': 'cs.CL, cs.LG',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Recent advancements in the NLP field showed that transfer learning helps with\\nachieving state-of-the-art results for new tasks by tuning pre-trained models\\ninstead of starting from scratch. Transformers have made a significant\\nimprovement in creating new state-of-the-art results for many NLP tasks\\nincluding but not limited to text classification, text generation, and sequence\\nlabeling. Most of these success stories were based on large datasets. In this\\npaper we focus on a real-life scenario that scientists in academia and industry\\nface frequently: given a small dataset, can we use a large pre-trained model\\nlike BERT and get better results than simple models? To answer this question,\\nwe use a small dataset for intent classification collected for building\\nchatbots and compare the performance of a simple bidirectional LSTM model with\\na pre-trained BERT model. Our experimental results show that bidirectional LSTM\\nmodels can achieve significantly higher results than a BERT model for a small\\ndataset and these simple models get trained in much less time than tuning the\\npre-trained counterparts. We conclude that the performance of a model is\\ndependent on the task and the data, and therefore before making a model choice,\\nthese factors should be taken into consideration instead of directly choosing\\nthe most popular model.'},\n",
       " {'title': 'Paranoid Transformer: Reading Narrative of Madness as Computational\\n  Approach to Creativity',\n",
       "  'pubdate': datetime.datetime(2020, 7, 13, 10, 18, 24, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2007.06290v1',\n",
       "  'authors': 'Yana Agafonova, Alexey Tikhonov, Ivan P. Yamshchikov',\n",
       "  'categories': 'cs.CL, cs.AI, cs.CY, 68T50, 68T07, 91F20, 68T42, H.1.2; J.5; K.4',\n",
       "  'search': 'story',\n",
       "  'abstract': 'This papers revisits the receptive theory in context of computational\\ncreativity. It presents a case study of a Paranoid Transformer - a fully\\nautonomous text generation engine with raw output that could be read as the\\nnarrative of a mad digital persona without any additional human post-filtering.\\nWe describe technical details of the generative system, provide examples of\\noutput and discuss the impact of receptive theory, chance discovery and\\nsimulation of fringe mental state on the understanding of computational\\ncreativity.'},\n",
       " {'title': 'On Faithfulness and Factuality in Abstractive Summarization',\n",
       "  'pubdate': datetime.datetime(2020, 5, 2, 0, 9, 16, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2005.00661v1',\n",
       "  'authors': 'Joshua Maynez, Shashi Narayan, Bernd Bohnet, Ryan McDonald',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'It is well known that the standard likelihood training and approximate\\ndecoding objectives in neural text generation models lead to less human-like\\nresponses for open-ended tasks such as language modeling and story generation.\\nIn this paper we have analyzed limitations of these models for abstractive\\ndocument summarization and found that these models are highly prone to\\nhallucinate content that is unfaithful to the input document. We conducted a\\nlarge scale human evaluation of several neural abstractive summarization\\nsystems to better understand the types of hallucinations they produce. Our\\nhuman annotators found substantial amounts of hallucinated content in all model\\ngenerated summaries. However, our analysis does show that pretrained models are\\nbetter summarizers not only in terms of raw metrics, i.e., ROUGE, but also in\\ngenerating faithful and factual summaries as evaluated by humans. Furthermore,\\nwe show that textual entailment measures better correlate with faithfulness\\nthan standard metrics, potentially leading the way to automatic evaluation\\nmetrics as well as training and decoding criteria.'},\n",
       " {'title': 'Semantics of the Unwritten',\n",
       "  'pubdate': datetime.datetime(2020, 4, 5, 16, 55, 9, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/2004.02251v1',\n",
       "  'authors': 'He Bai, Peng Shi, Jimmy Lin, Luchen Tan, Kun Xiong, Wen Gao, Jie Liu, Ming Li',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'The semantics of a text is manifested not only by what is read, but also by\\nwhat is not read. In this article, we will study how those implicit \"not read\"\\ninformation such as end-of-paragraph (EOP) and end-of-sequence (EOS) affect the\\nquality of text generation. Transformer-based pretrained language models (LMs)\\nhave demonstrated the ability to generate long continuations with good quality.\\nThis model gives us a platform for the first time to demonstrate that paragraph\\nlayouts and text endings are also important components of human writing.\\nSpecifically, we find that pretrained LMs can generate better continuations by\\nlearning to generate the end of the paragraph (EOP) in the fine-tuning stage.\\nExperimental results on English story generation show that EOP can lead to\\nhigher BLEU score and lower EOS perplexity. To further investigate the\\nrelationship between text ending and EOP, we conduct experiments with a\\nself-collected Chinese essay dataset on Chinese-GPT2, a character level LM\\nwithout paragraph breaker or EOS during pre-training. Experimental results show\\nthat the Chinese GPT2 can generate better essay endings with paragraph\\ninformation. Experiments on both English stories and Chinese essays demonstrate\\nthat learning to end paragraphs can benefit the continuation generation with\\npretrained LMs.'},\n",
       " {'title': 'Counterfactual Story Reasoning and Generation',\n",
       "  'pubdate': datetime.datetime(2019, 9, 9, 18, 8, 35, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/1909.04076v2',\n",
       "  'authors': 'Lianhui Qin, Antoine Bosselut, Ari Holtzman, Chandra Bhagavatula, Elizabeth Clark, Yejin Choi',\n",
       "  'categories': 'cs.CL, cs.AI',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Counterfactual reasoning requires predicting how alternative events, contrary\\nto what actually happened, might have resulted in different outcomes. Despite\\nbeing considered a necessary component of AI-complete systems, few resources\\nhave been developed for evaluating counterfactual reasoning in narratives.\\n  In this paper, we propose Counterfactual Story Rewriting: given an original\\nstory and an intervening counterfactual event, the task is to minimally revise\\nthe story to make it compatible with the given counterfactual event. Solving\\nthis task will require deep understanding of causal narrative chains and\\ncounterfactual invariance, and integration of such story reasoning capabilities\\ninto conditional language generation models.\\n  We present TimeTravel, a new dataset of 29,849 counterfactual rewritings,\\neach with the original story, a counterfactual event, and human-generated\\nrevision of the original story compatible with the counterfactual event.\\nAdditionally, we include 80,115 counterfactual \"branches\" without a rewritten\\nstoryline to support future work on semi- or un-supervised approaches to\\ncounterfactual story rewriting.\\n  Finally, we evaluate the counterfactual rewriting capacities of several\\ncompetitive baselines based on pretrained language models, and assess whether\\ncommon overlap and model-based automatic metrics for text generation correlate\\nwell with human scores for counterfactual rewriting.'},\n",
       " {'title': 'WriterForcing: Generating more interesting story endings',\n",
       "  'pubdate': datetime.datetime(2019, 7, 18, 19, 29, 29, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/1907.08259v1',\n",
       "  'authors': 'Prakhar Gupta, Vinayshekhar Bannihatti Kumar, Mukul Bhutani, Alan W Black',\n",
       "  'categories': 'cs.LG, cs.CL, stat.ML',\n",
       "  'search': 'story',\n",
       "  'abstract': 'We study the problem of generating interesting endings for stories. Neural\\ngenerative models have shown promising results for various text generation\\nproblems. Sequence to Sequence (Seq2Seq) models are typically trained to\\ngenerate a single output sequence for a given input sequence. However, in the\\ncontext of a story, multiple endings are possible. Seq2Seq models tend to\\nignore the context and generate generic and dull responses. Very few works have\\nstudied generating diverse and interesting story endings for a given story\\ncontext. In this paper, we propose models which generate more diverse and\\ninteresting outputs by 1) training models to focus attention on important\\nkeyphrases of the story, and 2) promoting generation of non-generic words. We\\nshow that the combination of the two leads to more diverse and interesting\\nendings.'},\n",
       " {'title': 'Strategies for Structuring Story Generation',\n",
       "  'pubdate': datetime.datetime(2019, 2, 4, 10, 23, 39, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/1902.01109v2',\n",
       "  'authors': 'Angela Fan, Mike Lewis, Yann Dauphin',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Writers generally rely on plans or sketches to write long stories, but most\\ncurrent language models generate word by word from left to right. We explore\\ncoarse-to-fine models for creating narrative texts of several hundred words,\\nand introduce new models which decompose stories by abstracting over actions\\nand entities. The model first generates the predicate-argument structure of the\\ntext, where different mentions of the same entity are marked with placeholder\\ntokens. It then generates a surface realization of the predicate-argument\\nstructure, and finally replaces the entity placeholders with context-sensitive\\nnames and references. Human judges prefer the stories from our models to a wide\\nrange of previous approaches to hierarchical text generation. Extensive\\nanalysis shows that our methods can help improve the diversity and coherence of\\nevents and entities in generated stories.'},\n",
       " {'title': 'Towards Content Transfer through Grounded Text Generation',\n",
       "  'pubdate': datetime.datetime(2019, 5, 13, 21, 36, 43, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/1905.05293v1',\n",
       "  'authors': 'Shrimai Prabhumoye, Chris Quirk, Michel Galley',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Recent work in neural generation has attracted significant interest in\\ncontrolling the form of text, such as style, persona, and politeness. However,\\nthere has been less work on controlling neural text generation for content.\\nThis paper introduces the notion of Content Transfer for long-form text\\ngeneration, where the task is to generate a next sentence in a document that\\nboth fits its context and is grounded in a content-rich external textual source\\nsuch as a news story. Our experiments on Wikipedia data show significant\\nimprovements against competitive baselines. As another contribution of this\\npaper, we release a benchmark dataset of 640k Wikipedia referenced sentences\\npaired with the source articles to encourage exploration of this new task.'},\n",
       " {'title': 'Co-occurrence of the Benford-like and Zipf Laws Arising from the Texts\\n  Representing Human and Artificial Languages',\n",
       "  'pubdate': datetime.datetime(2018, 3, 6, 12, 24, 42, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/1803.03667v1',\n",
       "  'authors': 'Evgeny Shulzinger, Irina Legchenkova, Edward Bormashenko',\n",
       "  'categories': 'cs.CL, physics.soc-ph, stat.OT',\n",
       "  'search': 'story',\n",
       "  'abstract': 'We demonstrate that large texts, representing human (English, Russian,\\nUkrainian) and artificial (C++, Java) languages, display quantitative patterns\\ncharacterized by the Benford-like and Zipf laws. The frequency of a word\\nfollowing the Zipf law is inversely proportional to its rank, whereas the total\\nnumbers of a certain word appearing in the text generate the uneven\\nBenford-like distribution of leading numbers. Excluding the most popular words\\nessentially improves the correlation of actual textual data with the Zipfian\\ndistribution, whereas the Benford distribution of leading numbers (arising from\\nthe overall amount of a certain word) is insensitive to the same elimination\\nprocedure. The calculated values of the moduli of slopes of double\\nlogarithmical plots for artificial languages (C++, Java) are markedly larger\\nthan those for human ones.'},\n",
       " {'title': 'Story Generation from Sequence of Independent Short Descriptions',\n",
       "  'pubdate': datetime.datetime(2017, 7, 18, 7, 8, 31, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/1707.05501v2',\n",
       "  'authors': 'Parag Jain, Priyanka Agrawal, Abhijit Mishra, Mohak Sukhwani, Anirban Laha, Karthik Sankaranarayanan',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': \"Existing Natural Language Generation (NLG) systems are weak AI systems and\\nexhibit limited capabilities when language generation tasks demand higher\\nlevels of creativity, originality and brevity. Effective solutions or, at least\\nevaluations of modern NLG paradigms for such creative tasks have been elusive,\\nunfortunately. This paper introduces and addresses the task of coherent story\\ngeneration from independent descriptions, describing a scene or an event.\\nTowards this, we explore along two popular text-generation paradigms -- (1)\\nStatistical Machine Translation (SMT), posing story generation as a translation\\nproblem and (2) Deep Learning, posing story generation as a sequence to\\nsequence learning problem. In SMT, we chose two popular methods such as phrase\\nbased SMT (PB-SMT) and syntax based SMT (SYNTAX-SMT) to `translate' the\\nincoherent input text into stories. We then implement a deep recurrent neural\\nnetwork (RNN) architecture that encodes sequence of variable length input\\ndescriptions to corresponding latent representations and decodes them to\\nproduce well formed comprehensive story like summaries. The efficacy of the\\nsuggested approaches is demonstrated on a publicly available dataset with the\\nhelp of popular machine translation and summarization evaluation metrics.\"},\n",
       " {'title': 'A Theme-Rewriting Approach for Generating Algebra Word Problems',\n",
       "  'pubdate': datetime.datetime(2016, 10, 19, 20, 49, 23, tzinfo=tzutc()),\n",
       "  'id': 'http://arxiv.org/abs/1610.06210v1',\n",
       "  'authors': 'Rik Koncel-Kedziorski, Ioannis Konstas, Luke Zettlemoyer, Hannaneh Hajishirzi',\n",
       "  'categories': 'cs.CL',\n",
       "  'search': 'story',\n",
       "  'abstract': 'Texts present coherent stories that have a particular theme or overall\\nsetting, for example science fiction or western. In this paper, we present a\\ntext generation method called {\\\\it rewriting} that edits existing\\nhuman-authored narratives to change their theme without changing the underlying\\nstory. We apply the approach to math word problems, where it might help\\nstudents stay more engaged by quickly transforming all of their homework\\nassignments to the theme of their favorite movie without changing the math\\nconcepts that are being taught. Our rewriting method uses a two-stage decoding\\nprocess, which proposes new words from the target theme and scores the\\nresulting stories according to a number of factors defining aspects of\\nsyntactic, semantic, and thematic coherence. Experiments demonstrate that the\\nfinal stories typically represent the new theme well while still testing the\\noriginal math concepts, outperforming a number of baselines. We also release a\\nnew dataset of human-authored rewrites of math word problems in several themes.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-12 story 23\n",
      "no new data to write\n",
      "2021-01-12 table2text 44\n",
      "writing new file 2021-01-13\n",
      "2021-01-12 games 10\n",
      "no new data to write\n",
      "2021-01-12 dialogue 30\n",
      "no new data to write\n",
      "2021-01-12 knowledge 33\n",
      "writing new file 2021-01-13\n",
      "2021-01-12 poetry 10\n",
      "no new data to write\n",
      "2021-01-12 image2text 74\n",
      "no new data to write\n"
     ]
    }
   ],
   "source": [
    "for key, vals in arts2.items():\n",
    "    write_data(key, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021-01-05-table2text-100', '2021-01-12-table2text-44']\n",
      "2021-01-12 table2text 44\n",
      "('2021-01-12', 'table2text', '44')\n"
     ]
    }
   ],
   "source": [
    "merge_with_previous(\"table2text\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-04-11',\n",
       " '2019-08-20-story',\n",
       " '2019-08-23-dialogue',\n",
       " '2020-01-30-story',\n",
       " '2020-08-20-dialogue',\n",
       " '2020-11-19-abs']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(['2020-01-30-story', '2019-08-23-dialogue', '2019-04-11','2019-08-20-story', '2020-08-20-dialogue', '2020-11-19-abs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv(\"_data/2020-04-21-tables-44.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>search</th>\n",
       "      <th>displaydate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learning to Encode Evolutionary Knowledge for ...</td>\n",
       "      <td>2020-04-21 13:09:50+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2004.09974v1</td>\n",
       "      <td>Canxiang Yan, Jianhao Yan, Yangyin Xu, Cheng N...</td>\n",
       "      <td>cs.CL, cs.LG</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Data-to-Text Generation with Dynamic Co...</td>\n",
       "      <td>2020-04-16 02:50:51+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2004.07426v2</td>\n",
       "      <td>Kai Chen, Fayuan Li, Baotian Hu, Weihua Peng, ...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Translation Pre-training for Data-to-T...</td>\n",
       "      <td>2020-04-05 02:47:16+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2004.02077v1</td>\n",
       "      <td>Mihir Kale, Scott Roy</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG-BERT: Conditional Text Generation with BERT...</td>\n",
       "      <td>2020-04-04 07:31:59+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2004.01881v1</td>\n",
       "      <td>Congying Xia, Chenwei Zhang, Hoang Nguyen, Jia...</td>\n",
       "      <td>cs.CL, cs.LG</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heavy-tailed Representations, Text Polarity Cl...</td>\n",
       "      <td>2020-03-25 19:24:05+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2003.11593v1</td>\n",
       "      <td>Hamid Jalalzai, Pierre Colombo, Chloé Clavel, ...</td>\n",
       "      <td>stat.ML, cs.CL, cs.LG</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unsupervised Pidgin Text Generation By Pivotin...</td>\n",
       "      <td>2020-03-18 15:27:35+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2003.08272v1</td>\n",
       "      <td>Ernie Chang, David Ifeoluwa Adelani, Xiaoyu Sh...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Generating Major Types of Chinese Classical Po...</td>\n",
       "      <td>2020-03-13 14:16:25+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2003.11528v1</td>\n",
       "      <td>Jinyi Hu, Maosong Sun</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Meta-CoTGAN: A Meta Cooperative Training Parad...</td>\n",
       "      <td>2020-03-12 04:47:52+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2003.11530v1</td>\n",
       "      <td>Haiyan Yin, Dingcheng Li, Xu Li, Ping Li</td>\n",
       "      <td>cs.CL, cs.LG, stat.ML</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-03-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Generating Natural Language Adversarial Exampl...</td>\n",
       "      <td>2020-03-10 03:21:35+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2003.10388v1</td>\n",
       "      <td>Yankun Ren, Jianbin Lin, Siliang Tang, Jun Zho...</td>\n",
       "      <td>cs.CL, cs.LG, stat.ML</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Plug and Play Language Models: A Simple Approa...</td>\n",
       "      <td>2019-12-04 18:32:15+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1912.02164v4</td>\n",
       "      <td>Sumanth Dathathri, Andrea Madotto, Janice Lan,...</td>\n",
       "      <td>cs.CL, cs.AI, cs.LG</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CoTK: An Open-Source Toolkit for Fast Developm...</td>\n",
       "      <td>2020-02-03 07:15:29+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2002.00583v1</td>\n",
       "      <td>Fei Huang, Dazhen Wan, Zhihong Shao, Pei Ke, J...</td>\n",
       "      <td>cs.CL, cs.LG, I.2.7</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Multimodal Story Generation on Plural Images</td>\n",
       "      <td>2020-01-16 03:39:00+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2001.10980v1</td>\n",
       "      <td>Jing Jiang</td>\n",
       "      <td>cs.CL, cs.CV, cs.LG, stat.ML</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Revisiting Challenges in Data-to-Text Generati...</td>\n",
       "      <td>2020-01-12 02:31:07+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2001.03830v1</td>\n",
       "      <td>Hongmin Wang</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PatentTransformer-2: Controlling Patent Text G...</td>\n",
       "      <td>2020-01-11 03:54:31+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2001.03708v1</td>\n",
       "      <td>Jieh-Sheng Lee, Jieh Hsiang</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Paraphrase Generation with Latent Bag of Words</td>\n",
       "      <td>2020-01-07 09:22:58+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2001.01941v1</td>\n",
       "      <td>Yao Fu, Yansong Feng, John P. Cunningham</td>\n",
       "      <td>cs.CL, cs.LG</td>\n",
       "      <td>tables</td>\n",
       "      <td>2020-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bootstrapping Generators from Noisy Data</td>\n",
       "      <td>2018-04-17 17:30:02+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1804.06385v4</td>\n",
       "      <td>Laura Perez-Beltrachini, Mirella Lapata</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2018-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Personalized Patent Claim Generation and Measu...</td>\n",
       "      <td>2019-12-07 13:26:18+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1912.03502v2</td>\n",
       "      <td>Jieh-Sheng Lee</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AMR-to-Text Generation with Cache Transition S...</td>\n",
       "      <td>2019-12-03 20:45:04+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1912.01682v1</td>\n",
       "      <td>Lisa Jin, Daniel Gildea</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Neural Academic Paper Generation</td>\n",
       "      <td>2019-12-02 18:45:23+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1912.01982v1</td>\n",
       "      <td>Samet Demir, Uras Mutlu, Özgur Özdemir</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Graph Transformer for Graph-to-Sequence Learning</td>\n",
       "      <td>2019-11-18 07:45:19+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1911.07470v2</td>\n",
       "      <td>Deng Cai, Wai Lam</td>\n",
       "      <td>cs.CL, cs.AI</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Implicit Deep Latent Variable Models for Text ...</td>\n",
       "      <td>2019-08-30 04:12:08+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1908.11527v3</td>\n",
       "      <td>Le Fang, Chunyuan Li, Jianfeng Gao, Wen Dong, ...</td>\n",
       "      <td>cs.LG, cs.CL, stat.ML</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Neural data-to-text generation: A comparison b...</td>\n",
       "      <td>2019-08-23 20:10:36+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1908.09022v2</td>\n",
       "      <td>Thiago Castro Ferreira, Chris van der Lee, Emi...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Not Enough Data? Deep Learning to the Rescue!</td>\n",
       "      <td>2019-11-08 08:30:22+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1911.03118v2</td>\n",
       "      <td>Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldb...</td>\n",
       "      <td>cs.CL, cs.LG</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Improving N-gram Language Models with Pre-trai...</td>\n",
       "      <td>2019-11-22 20:11:40+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1911.10235v1</td>\n",
       "      <td>Yiren Wang, Hongzhao Huang, Zhe Liu, Yutong Pa...</td>\n",
       "      <td>cs.CL, cs.LG</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-11-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CatGAN: Category-aware Generative Adversarial ...</td>\n",
       "      <td>2019-11-15 14:03:30+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1911.06641v2</td>\n",
       "      <td>Zhiyue Liu, Jiahai Wang, Zhiwei Liang</td>\n",
       "      <td>cs.CL, cs.LG, cs.NE</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Stylized Text Generation Using Wasserstein Aut...</td>\n",
       "      <td>2019-11-10 02:06:23+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1911.03828v1</td>\n",
       "      <td>Amirpasha Ghabussi, Lili Mou, Olga Vechtomova</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Conditioned Query Generation for Task-Oriented...</td>\n",
       "      <td>2019-11-09 14:22:57+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1911.03698v1</td>\n",
       "      <td>Stéphane d'Ascoli, Alice Coucke, Francesco Cal...</td>\n",
       "      <td>cs.CL, cs.LG, stat.ML</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ask to Learn: A Study on Curiosity-driven Ques...</td>\n",
       "      <td>2019-11-08 16:17:40+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1911.03350v1</td>\n",
       "      <td>Thomas Scialom, Jacopo Staiano</td>\n",
       "      <td>cs.CL, cs.AI</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Controlled Text Generation for Data Augmentati...</td>\n",
       "      <td>2019-10-04 20:44:21+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1910.03487v1</td>\n",
       "      <td>Nikolaos Malandrakis, Minmin Shen, Anuj Goyal,...</td>\n",
       "      <td>cs.CL, cs.LG, stat.ML</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Clinical Text Generation through Leveraging Me...</td>\n",
       "      <td>2019-10-02 10:17:28+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1910.00861v1</td>\n",
       "      <td>Wangjin Lee, Hyeryun Park, Jooyoung Yoon, Kyeo...</td>\n",
       "      <td>cs.CL, cs.AI</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MoverScore: Text Generation Evaluating with Co...</td>\n",
       "      <td>2019-09-05 20:26:44+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.02622v2</td>\n",
       "      <td>Wei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, C...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Improving Quality and Efficiency in Plan-based...</td>\n",
       "      <td>2019-09-22 11:41:53+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.09986v1</td>\n",
       "      <td>Amit Moryossef, Ido Dagan, Yoav Goldberg</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CTRL: A Conditional Transformer Language Model...</td>\n",
       "      <td>2019-09-11 17:57:18+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.05858v2</td>\n",
       "      <td>Nitish Shirish Keskar, Bryan McCann, Lav R. Va...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Improved Variational Neural Machine Translatio...</td>\n",
       "      <td>2019-09-19 21:16:29+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.09237v1</td>\n",
       "      <td>Arya D. McCarthy, Xian Li, Jiatao Gu, Ning Dong</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>VizSeq: A Visual Analysis Toolkit for Text Gen...</td>\n",
       "      <td>2019-09-12 01:16:27+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.05424v1</td>\n",
       "      <td>Changhan Wang, Anirudh Jain, Danlu Chen, Jiata...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ER-AE: Differentially-private Text Generation ...</td>\n",
       "      <td>2019-07-20 02:07:02+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1907.08736v3</td>\n",
       "      <td>Haohan Bo, Steven H. H. Ding, Benjamin C. M. F...</td>\n",
       "      <td>cs.CR, cs.CL, cs.LG</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Encoder-Agnostic Adaptation for Conditional La...</td>\n",
       "      <td>2019-08-19 17:22:58+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1908.06938v2</td>\n",
       "      <td>Zachary M. Ziegler, Luke Melas-Kyriazi, Sebast...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Select and Attend: Towards Controllable Conten...</td>\n",
       "      <td>2019-09-10 12:59:10+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.04453v1</td>\n",
       "      <td>Xiaoyu Shen, Jun Suzuki, Kentaro Inui, Hui Su,...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Densely Connected Graph Convolutional Networks...</td>\n",
       "      <td>2019-08-16 12:58:16+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1908.05957v2</td>\n",
       "      <td>Zhijiang Guo, Yan Zhang, Zhiyang Teng, Wei Lu</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Table-to-Text Generation with Effective Hierar...</td>\n",
       "      <td>2019-09-05 10:25:34+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.02304v1</td>\n",
       "      <td>Heng Gong, Xiaocheng Feng, Bing Qin, Ting Liu</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Data-Driven Approach to Encoding and Decoding ...</td>\n",
       "      <td>2019-09-03 04:36:13+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.00949v1</td>\n",
       "      <td>Jordan Hoffmann, Louis Maestrati, Yoshihide Sa...</td>\n",
       "      <td>cs.LG, cond-mat.mtrl-sci, physics.comp-ph, sta...</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Enhancing AMR-to-Text Generation with Dual Gra...</td>\n",
       "      <td>2019-09-01 08:22:38+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.00352v1</td>\n",
       "      <td>Leonardo F. R. Ribeiro, Claire Gardent, Iryna ...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Modeling Graph Structure in Transformer for Be...</td>\n",
       "      <td>2019-08-31 05:45:20+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1909.00136v1</td>\n",
       "      <td>Jie Zhu, Junhui Li, Muhua Zhu, Longhua Qian, M...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A Hybrid Retrieval-Generation Neural Conversat...</td>\n",
       "      <td>2019-04-19 04:10:03+00:00</td>\n",
       "      <td>http://arxiv.org/abs/1904.09068v2</td>\n",
       "      <td>Liu Yang, Junjie Hu, Minghui Qiu, Chen Qu, Jia...</td>\n",
       "      <td>cs.IR, cs.CL</td>\n",
       "      <td>tables</td>\n",
       "      <td>2019-04-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Learning to Encode Evolutionary Knowledge for ...   \n",
       "1   Neural Data-to-Text Generation with Dynamic Co...   \n",
       "2   Machine Translation Pre-training for Data-to-T...   \n",
       "3   CG-BERT: Conditional Text Generation with BERT...   \n",
       "4   Heavy-tailed Representations, Text Polarity Cl...   \n",
       "5   Unsupervised Pidgin Text Generation By Pivotin...   \n",
       "6   Generating Major Types of Chinese Classical Po...   \n",
       "7   Meta-CoTGAN: A Meta Cooperative Training Parad...   \n",
       "8   Generating Natural Language Adversarial Exampl...   \n",
       "9   Plug and Play Language Models: A Simple Approa...   \n",
       "10  CoTK: An Open-Source Toolkit for Fast Developm...   \n",
       "11       Multimodal Story Generation on Plural Images   \n",
       "12  Revisiting Challenges in Data-to-Text Generati...   \n",
       "13  PatentTransformer-2: Controlling Patent Text G...   \n",
       "14     Paraphrase Generation with Latent Bag of Words   \n",
       "15           Bootstrapping Generators from Noisy Data   \n",
       "16  Personalized Patent Claim Generation and Measu...   \n",
       "17  AMR-to-Text Generation with Cache Transition S...   \n",
       "18                   Neural Academic Paper Generation   \n",
       "19   Graph Transformer for Graph-to-Sequence Learning   \n",
       "20  Implicit Deep Latent Variable Models for Text ...   \n",
       "21  Neural data-to-text generation: A comparison b...   \n",
       "22      Not Enough Data? Deep Learning to the Rescue!   \n",
       "23  Improving N-gram Language Models with Pre-trai...   \n",
       "24  CatGAN: Category-aware Generative Adversarial ...   \n",
       "25  Stylized Text Generation Using Wasserstein Aut...   \n",
       "26  Conditioned Query Generation for Task-Oriented...   \n",
       "27  Ask to Learn: A Study on Curiosity-driven Ques...   \n",
       "28  Controlled Text Generation for Data Augmentati...   \n",
       "29  Clinical Text Generation through Leveraging Me...   \n",
       "30  MoverScore: Text Generation Evaluating with Co...   \n",
       "31  Improving Quality and Efficiency in Plan-based...   \n",
       "32  CTRL: A Conditional Transformer Language Model...   \n",
       "33  Improved Variational Neural Machine Translatio...   \n",
       "34  VizSeq: A Visual Analysis Toolkit for Text Gen...   \n",
       "35  ER-AE: Differentially-private Text Generation ...   \n",
       "36  Encoder-Agnostic Adaptation for Conditional La...   \n",
       "37  Select and Attend: Towards Controllable Conten...   \n",
       "38  Densely Connected Graph Convolutional Networks...   \n",
       "39  Table-to-Text Generation with Effective Hierar...   \n",
       "40  Data-Driven Approach to Encoding and Decoding ...   \n",
       "41  Enhancing AMR-to-Text Generation with Dual Gra...   \n",
       "42  Modeling Graph Structure in Transformer for Be...   \n",
       "43  A Hybrid Retrieval-Generation Neural Conversat...   \n",
       "\n",
       "                      pubdate                                 id  \\\n",
       "0   2020-04-21 13:09:50+00:00  http://arxiv.org/abs/2004.09974v1   \n",
       "1   2020-04-16 02:50:51+00:00  http://arxiv.org/abs/2004.07426v2   \n",
       "2   2020-04-05 02:47:16+00:00  http://arxiv.org/abs/2004.02077v1   \n",
       "3   2020-04-04 07:31:59+00:00  http://arxiv.org/abs/2004.01881v1   \n",
       "4   2020-03-25 19:24:05+00:00  http://arxiv.org/abs/2003.11593v1   \n",
       "5   2020-03-18 15:27:35+00:00  http://arxiv.org/abs/2003.08272v1   \n",
       "6   2020-03-13 14:16:25+00:00  http://arxiv.org/abs/2003.11528v1   \n",
       "7   2020-03-12 04:47:52+00:00  http://arxiv.org/abs/2003.11530v1   \n",
       "8   2020-03-10 03:21:35+00:00  http://arxiv.org/abs/2003.10388v1   \n",
       "9   2019-12-04 18:32:15+00:00  http://arxiv.org/abs/1912.02164v4   \n",
       "10  2020-02-03 07:15:29+00:00  http://arxiv.org/abs/2002.00583v1   \n",
       "11  2020-01-16 03:39:00+00:00  http://arxiv.org/abs/2001.10980v1   \n",
       "12  2020-01-12 02:31:07+00:00  http://arxiv.org/abs/2001.03830v1   \n",
       "13  2020-01-11 03:54:31+00:00  http://arxiv.org/abs/2001.03708v1   \n",
       "14  2020-01-07 09:22:58+00:00  http://arxiv.org/abs/2001.01941v1   \n",
       "15  2018-04-17 17:30:02+00:00  http://arxiv.org/abs/1804.06385v4   \n",
       "16  2019-12-07 13:26:18+00:00  http://arxiv.org/abs/1912.03502v2   \n",
       "17  2019-12-03 20:45:04+00:00  http://arxiv.org/abs/1912.01682v1   \n",
       "18  2019-12-02 18:45:23+00:00  http://arxiv.org/abs/1912.01982v1   \n",
       "19  2019-11-18 07:45:19+00:00  http://arxiv.org/abs/1911.07470v2   \n",
       "20  2019-08-30 04:12:08+00:00  http://arxiv.org/abs/1908.11527v3   \n",
       "21  2019-08-23 20:10:36+00:00  http://arxiv.org/abs/1908.09022v2   \n",
       "22  2019-11-08 08:30:22+00:00  http://arxiv.org/abs/1911.03118v2   \n",
       "23  2019-11-22 20:11:40+00:00  http://arxiv.org/abs/1911.10235v1   \n",
       "24  2019-11-15 14:03:30+00:00  http://arxiv.org/abs/1911.06641v2   \n",
       "25  2019-11-10 02:06:23+00:00  http://arxiv.org/abs/1911.03828v1   \n",
       "26  2019-11-09 14:22:57+00:00  http://arxiv.org/abs/1911.03698v1   \n",
       "27  2019-11-08 16:17:40+00:00  http://arxiv.org/abs/1911.03350v1   \n",
       "28  2019-10-04 20:44:21+00:00  http://arxiv.org/abs/1910.03487v1   \n",
       "29  2019-10-02 10:17:28+00:00  http://arxiv.org/abs/1910.00861v1   \n",
       "30  2019-09-05 20:26:44+00:00  http://arxiv.org/abs/1909.02622v2   \n",
       "31  2019-09-22 11:41:53+00:00  http://arxiv.org/abs/1909.09986v1   \n",
       "32  2019-09-11 17:57:18+00:00  http://arxiv.org/abs/1909.05858v2   \n",
       "33  2019-09-19 21:16:29+00:00  http://arxiv.org/abs/1909.09237v1   \n",
       "34  2019-09-12 01:16:27+00:00  http://arxiv.org/abs/1909.05424v1   \n",
       "35  2019-07-20 02:07:02+00:00  http://arxiv.org/abs/1907.08736v3   \n",
       "36  2019-08-19 17:22:58+00:00  http://arxiv.org/abs/1908.06938v2   \n",
       "37  2019-09-10 12:59:10+00:00  http://arxiv.org/abs/1909.04453v1   \n",
       "38  2019-08-16 12:58:16+00:00  http://arxiv.org/abs/1908.05957v2   \n",
       "39  2019-09-05 10:25:34+00:00  http://arxiv.org/abs/1909.02304v1   \n",
       "40  2019-09-03 04:36:13+00:00  http://arxiv.org/abs/1909.00949v1   \n",
       "41  2019-09-01 08:22:38+00:00  http://arxiv.org/abs/1909.00352v1   \n",
       "42  2019-08-31 05:45:20+00:00  http://arxiv.org/abs/1909.00136v1   \n",
       "43  2019-04-19 04:10:03+00:00  http://arxiv.org/abs/1904.09068v2   \n",
       "\n",
       "                                              authors  \\\n",
       "0   Canxiang Yan, Jianhao Yan, Yangyin Xu, Cheng N...   \n",
       "1   Kai Chen, Fayuan Li, Baotian Hu, Weihua Peng, ...   \n",
       "2                               Mihir Kale, Scott Roy   \n",
       "3   Congying Xia, Chenwei Zhang, Hoang Nguyen, Jia...   \n",
       "4   Hamid Jalalzai, Pierre Colombo, Chloé Clavel, ...   \n",
       "5   Ernie Chang, David Ifeoluwa Adelani, Xiaoyu Sh...   \n",
       "6                               Jinyi Hu, Maosong Sun   \n",
       "7            Haiyan Yin, Dingcheng Li, Xu Li, Ping Li   \n",
       "8   Yankun Ren, Jianbin Lin, Siliang Tang, Jun Zho...   \n",
       "9   Sumanth Dathathri, Andrea Madotto, Janice Lan,...   \n",
       "10  Fei Huang, Dazhen Wan, Zhihong Shao, Pei Ke, J...   \n",
       "11                                         Jing Jiang   \n",
       "12                                       Hongmin Wang   \n",
       "13                        Jieh-Sheng Lee, Jieh Hsiang   \n",
       "14           Yao Fu, Yansong Feng, John P. Cunningham   \n",
       "15            Laura Perez-Beltrachini, Mirella Lapata   \n",
       "16                                     Jieh-Sheng Lee   \n",
       "17                            Lisa Jin, Daniel Gildea   \n",
       "18             Samet Demir, Uras Mutlu, Özgur Özdemir   \n",
       "19                                  Deng Cai, Wai Lam   \n",
       "20  Le Fang, Chunyuan Li, Jianfeng Gao, Wen Dong, ...   \n",
       "21  Thiago Castro Ferreira, Chris van der Lee, Emi...   \n",
       "22  Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldb...   \n",
       "23  Yiren Wang, Hongzhao Huang, Zhe Liu, Yutong Pa...   \n",
       "24              Zhiyue Liu, Jiahai Wang, Zhiwei Liang   \n",
       "25      Amirpasha Ghabussi, Lili Mou, Olga Vechtomova   \n",
       "26  Stéphane d'Ascoli, Alice Coucke, Francesco Cal...   \n",
       "27                     Thomas Scialom, Jacopo Staiano   \n",
       "28  Nikolaos Malandrakis, Minmin Shen, Anuj Goyal,...   \n",
       "29  Wangjin Lee, Hyeryun Park, Jooyoung Yoon, Kyeo...   \n",
       "30  Wei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, C...   \n",
       "31           Amit Moryossef, Ido Dagan, Yoav Goldberg   \n",
       "32  Nitish Shirish Keskar, Bryan McCann, Lav R. Va...   \n",
       "33    Arya D. McCarthy, Xian Li, Jiatao Gu, Ning Dong   \n",
       "34  Changhan Wang, Anirudh Jain, Danlu Chen, Jiata...   \n",
       "35  Haohan Bo, Steven H. H. Ding, Benjamin C. M. F...   \n",
       "36  Zachary M. Ziegler, Luke Melas-Kyriazi, Sebast...   \n",
       "37  Xiaoyu Shen, Jun Suzuki, Kentaro Inui, Hui Su,...   \n",
       "38      Zhijiang Guo, Yan Zhang, Zhiyang Teng, Wei Lu   \n",
       "39      Heng Gong, Xiaocheng Feng, Bing Qin, Ting Liu   \n",
       "40  Jordan Hoffmann, Louis Maestrati, Yoshihide Sa...   \n",
       "41  Leonardo F. R. Ribeiro, Claire Gardent, Iryna ...   \n",
       "42  Jie Zhu, Junhui Li, Muhua Zhu, Longhua Qian, M...   \n",
       "43  Liu Yang, Junjie Hu, Minghui Qiu, Chen Qu, Jia...   \n",
       "\n",
       "                                           categories  search displaydate  \n",
       "0                                        cs.CL, cs.LG  tables  2020-04-21  \n",
       "1                                               cs.CL  tables  2020-04-16  \n",
       "2                                               cs.CL  tables  2020-04-05  \n",
       "3                                        cs.CL, cs.LG  tables  2020-04-04  \n",
       "4                               stat.ML, cs.CL, cs.LG  tables  2020-03-25  \n",
       "5                                               cs.CL  tables  2020-03-18  \n",
       "6                                               cs.CL  tables  2020-03-13  \n",
       "7                               cs.CL, cs.LG, stat.ML  tables  2020-03-12  \n",
       "8                               cs.CL, cs.LG, stat.ML  tables  2020-03-10  \n",
       "9                                 cs.CL, cs.AI, cs.LG  tables  2019-12-04  \n",
       "10                                cs.CL, cs.LG, I.2.7  tables  2020-02-03  \n",
       "11                       cs.CL, cs.CV, cs.LG, stat.ML  tables  2020-01-16  \n",
       "12                                              cs.CL  tables  2020-01-12  \n",
       "13                                              cs.CL  tables  2020-01-11  \n",
       "14                                       cs.CL, cs.LG  tables  2020-01-07  \n",
       "15                                              cs.CL  tables  2018-04-17  \n",
       "16                                              cs.CL  tables  2019-12-07  \n",
       "17                                              cs.CL  tables  2019-12-03  \n",
       "18                                              cs.CL  tables  2019-12-02  \n",
       "19                                       cs.CL, cs.AI  tables  2019-11-18  \n",
       "20                              cs.LG, cs.CL, stat.ML  tables  2019-08-30  \n",
       "21                                              cs.CL  tables  2019-08-23  \n",
       "22                                       cs.CL, cs.LG  tables  2019-11-08  \n",
       "23                                       cs.CL, cs.LG  tables  2019-11-22  \n",
       "24                                cs.CL, cs.LG, cs.NE  tables  2019-11-15  \n",
       "25                                              cs.CL  tables  2019-11-10  \n",
       "26                              cs.CL, cs.LG, stat.ML  tables  2019-11-09  \n",
       "27                                       cs.CL, cs.AI  tables  2019-11-08  \n",
       "28                              cs.CL, cs.LG, stat.ML  tables  2019-10-04  \n",
       "29                                       cs.CL, cs.AI  tables  2019-10-02  \n",
       "30                                              cs.CL  tables  2019-09-05  \n",
       "31                                              cs.CL  tables  2019-09-22  \n",
       "32                                              cs.CL  tables  2019-09-11  \n",
       "33                                              cs.CL  tables  2019-09-19  \n",
       "34                                              cs.CL  tables  2019-09-12  \n",
       "35                                cs.CR, cs.CL, cs.LG  tables  2019-07-20  \n",
       "36                                              cs.CL  tables  2019-08-19  \n",
       "37                                              cs.CL  tables  2019-09-10  \n",
       "38                                              cs.CL  tables  2019-08-16  \n",
       "39                                              cs.CL  tables  2019-09-05  \n",
       "40  cs.LG, cond-mat.mtrl-sci, physics.comp-ph, sta...  tables  2019-09-03  \n",
       "41                                              cs.CL  tables  2019-09-01  \n",
       "42                                              cs.CL  tables  2019-08-31  \n",
       "43                                       cs.IR, cs.CL  tables  2019-04-19  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'id', 'authors', 'categories'], dtype='object')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_date_path(date):\n",
    "    return date.replace('-', '/') + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the page ends up published by category - add to a data file?\n",
    "def make_entry_for_md(date, categ):\n",
    "    filepath = 'categories/' + categ + '/' + make_date_path(date) + categ + '.html'\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_table_in_md(df, handle):\n",
    "    df = df[['title', 'authors', 'categories', 'id', 'displaydate']]\n",
    "    headers = list(df.columns)\n",
    "    headers.remove('id')\n",
    "    handle.write(\"\\n\")\n",
    "    handle.write(f\"### Written on {today}\\n\\n\")\n",
    "    handle.write('| ' + ' | '.join(headers) + \" |\\n\")\n",
    "    handle.write('| ' + ' | '.join(['-----' for x in range(len(headers))]) + ' |\\n')\n",
    "    for i, row in df.iterrows():\n",
    "        title = row['title'].replace('\\n','')\n",
    "        titlelink = f\"[{title}]({row['id']})\"\n",
    "        authors = row['authors']\n",
    "        categories = row['categories']\n",
    "        ddate = row['displaydate']\n",
    "        items = [titlelink, authors, categories, ddate]\n",
    "        handle.write('| ' + ' | '.join(items) + ' |\\n')\n",
    "    handle.write('\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "def write_table_md(df, date, categ, prevlink, most_recent=False):\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    with open('categories/' + categ + '/_posts/' + date + '-' + categ + '.md', 'w') as handle:\n",
    "        handle.write(\"---\\n\")\n",
    "        handle.write('category: ' + categ + '\\n')\n",
    "        handle.write('layout: post\\n')\n",
    "        handle.write('sidebar:\\n')\n",
    "        handle.write('  nav: contents\\n')\n",
    "        handle.write('---\\n\\n')\n",
    "        write_table_in_md(df, handle)\n",
    "        if type(prevlink) == str:\n",
    "            handle.write(f'[Previous]({prevlink})\\n')\n",
    "    if most_recent:\n",
    "        # write the main page too\n",
    "        with open('categories/' + categ + '/' + categ + '.md', 'w') as handle:\n",
    "            handle.write(\"---\\n\")\n",
    "            handle.write('category: ' + categ + '\\n')\n",
    "            handle.write('layout: page\\n')\n",
    "            handle.write('title:' + categ + '\\n')\n",
    "            handle.write('sidebar:\\n')\n",
    "            handle.write('  nav: contents\\n')\n",
    "            handle.write('---\\n\\n')\n",
    "            write_table_in_md(df, handle)\n",
    "            if type(prevlink) == str:\n",
    "                handle.write(f'[Previous]({prevlink})\\n')\n",
    "    print(\"wrote \", 'categories/' + categ + '/_posts/' + date + '-' + categ + '.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = !ls _data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_table_md(data, 'table2text', today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ls: _data/*.csv: No such file or directory']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_prev_files(date, category):\n",
    "    print(\"would here delete\", date, category)\n",
    "    rem_file = Path(f\"categories/{category}/_posts/{date}-{category}.md\")\n",
    "    if rem_file.is_file():\n",
    "        #rem_file.unlink()\n",
    "        print('would delete', rem_file)\n",
    "    rem_data_files = Path(f\"_data/{category}/\").glob(f\"{date}-{category}*.csv\")\n",
    "    rem_data_files = [str(x) for x in rem_data_files]\n",
    "    if rem_data_files[0]:\n",
    "        #Path(rem_data_file[0]).unlink()\n",
    "        print('would delete', rem_data_files[0])\n",
    "    (year, month, day) = date.split('-')\n",
    "    rem_html_file = Path(f\"_site/{category}/{year}/{month}/{day}/{category}.html\")\n",
    "    if rem_html_file.is_file():\n",
    "        #rem_data_file[0].unlink()\n",
    "        print('would delete', rem_html_file)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_filedate(date, category):\n",
    "    path = Path(f\"categories/{category}/_posts/{date}-{category}.md\")\n",
    "    if path.is_file():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename):\n",
    "    path = Path(filename)\n",
    "    parts = path.stem.split('-')\n",
    "    date = '-'.join(parts[0:3])\n",
    "    cat = parts[3]\n",
    "    try:\n",
    "        count = parts[4]\n",
    "    except:\n",
    "        count = None\n",
    "    print(date, cat, count)\n",
    "    return (date, cat, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['story', 'table2text', 'games', 'dialogue', 'knowledge', 'poetry', 'image2text'])"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categs = arts2.keys()\n",
    "categs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_datafile(categ):\n",
    "    files = Path(f'_data/{categ}/').glob(\"*\" + categ + \"*.csv\")\n",
    "    files = sorted([str(file) for file in files])\n",
    "    print(\"all files for categ\", files)\n",
    "    print(\"most recent\", files[-1])\n",
    "    return files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all files for categ ['_data/story/2021-01-12-story-23.csv']\n",
      "most recent _data/story/2021-01-12-story-23.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'_data/story/2021-01-12-story-23.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_latest_datafile(\"story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "newdata = get_new_data('story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_written_files_categ(categ):\n",
    "    df = pd.read_csv(\"_data/files_written.csv\")\n",
    "    categs = df.groupby('category')\n",
    "    return categs.get_group(categ).sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prevdate_from_record(prevdate, categ):\n",
    "    # also remove prev data file?  fix new prevlinks\n",
    "    df = pd.read_csv(\"_data/files_written.csv\")\n",
    "    df.set_index('md_filename', inplace=True)\n",
    "    print(\"would delete here:\", df.loc[f\"{prevdate}-{categ}.md\"], len(df))\n",
    "    #del df.loc[f\"{prevdate}-{categ}.md\"]\n",
    "    print(len(df))\n",
    "    df.to_csv(\"_data/files_written.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_record_get_prevlink(newdate, categ):\n",
    "    df = pd.read_csv(\"_data/files_written.csv\")\n",
    "    subset = df[df['category'] == categ]\n",
    "    subset.sort_values(by=\"date\", ascending=False)\n",
    "    prevlink = subset.iloc[0]['generated_file']\n",
    "    generated_file = make_entry_for_md(newdate, categ)\n",
    "    md_filename = f\"{newdate}-{categ}.md\"\n",
    "    print('adding to record file', newdate, categ, md_filename, generated_file)\n",
    "    df = df.append({'date': newdate, 'category': categ, 'md_filename': md_filename, 'generated_file': generated_file},\n",
    "             ignore_index=True)\n",
    "    df.to_csv(\"_data/files_written.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>md_filename</th>\n",
       "      <th>generated_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>story</td>\n",
       "      <td>2021-01-12-story.md</td>\n",
       "      <td>_site/categories/story/2021/01/12/story.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>story</td>\n",
       "      <td>2021-01-05-story.md</td>\n",
       "      <td>_site/categories/story/2021/01/05/story.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date category          md_filename  \\\n",
       "14  2021-01-12    story  2021-01-12-story.md   \n",
       "13  2021-01-05    story  2021-01-05-story.md   \n",
       "\n",
       "                                  generated_file  \n",
       "14  _site/categories/story/2021/01/12/story.html  \n",
       "13  _site/categories/story/2021/01/05/story.html  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_written_files_categ('story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "all files for categ ['_data/knowledge/1994-05-24-knowledge-100.csv', '_data/knowledge/2019-03-27-knowledge-33.csv', '_data/knowledge/2021-01-05-knowledge-100.csv']\n",
      "most recent _data/knowledge/2021-01-05-knowledge-100.csv\n",
      "2021-01-05 knowledge 100\n",
      "writing new file 2021-01-17\n",
      "newdates ['2021-01-17']\n",
      "would here delete 2021-01-05 knowledge\n",
      "would delete categories/knowledge/_posts/2021-01-05-knowledge.md\n",
      "would delete _data/knowledge/2021-01-05-knowledge-100.csv\n",
      "would delete here: date                                                     2021-01-05\n",
      "category                                                  knowledge\n",
      "generated_file    _site/categories/knowledge/2021/01/05/knowledg...\n",
      "Name: 2021-01-05-knowledge.md, dtype: object 15\n",
      "15\n",
      "doing date 2021-01-17\n",
      "adding to record file 2021-01-17 knowledge 2021-01-17-knowledge.md _site/categories/knowledge/2021/01/17/knowledge.html\n",
      "prevlink None\n",
      "len of df 47\n",
      "                                               title  \\\n",
      "0  Political Depolarization of News Articles Usin...   \n",
      "1  Outline to Story: Fine-grained Controllable St...   \n",
      "2  DISCOS: Bridging the Gap between Discourse Kno...   \n",
      "3  A Graph Total Variation Regularized Softmax fo...   \n",
      "4  A Distributional Approach to Controlled Text G...   \n",
      "\n",
      "                     pubdate                                 id  \\\n",
      "0  2021-01-05 07:39:12+00:00  http://arxiv.org/abs/2101.01391v1   \n",
      "1  2021-01-04 08:16:21+00:00  http://arxiv.org/abs/2101.00822v1   \n",
      "2  2021-01-01 03:30:38+00:00  http://arxiv.org/abs/2101.00154v1   \n",
      "3  2021-01-01 03:29:21+00:00  http://arxiv.org/abs/2101.00153v1   \n",
      "4  2020-12-21 19:02:41+00:00  http://arxiv.org/abs/2012.11635v1   \n",
      "\n",
      "                                             authors           categories  \\\n",
      "0  Ruibo Liu, Lili Wang, Chenyan Jia, Soroush Vos...         cs.CL, cs.AI   \n",
      "1  Le Fang, Tao Zeng, Chaochun Liu, Liefeng Bo, W...  cs.CL, cs.AI, cs.LG   \n",
      "2  Tianqing Fang, Hongming Zhang, Weiqi Wang, Yan...         cs.CL, cs.AI   \n",
      "3                  Liu Bin, Wang Liang, Yin Guosheng                cs.CL   \n",
      "4      Muhammad Khalifa, Hady Elsahar, Marc Dymetman  cs.CL, cs.AI, cs.LG   \n",
      "\n",
      "      search                                           abstract displaydate  \n",
      "0  knowledge  Political polarization in the US is on the ris...  2021-01-05  \n",
      "1  knowledge  Large-scale pretrained language models have sh...  2021-01-04  \n",
      "2  knowledge  Commonsense knowledge is crucial for artificia...  2021-01-01  \n",
      "3  knowledge  The softmax operator is one of the most import...  2021-01-01  \n",
      "4  knowledge  We propose a Distributional Approach to addres...  2020-12-21  \n",
      "wrote  categories/knowledge/_posts/2021-01-17-knowledge.md\n"
     ]
    }
   ],
   "source": [
    "# get new data\n",
    "\n",
    "# HAVE SCRAPED\n",
    "categ = 'knowledge'\n",
    "newdata = get_new_data(categ)\n",
    "\n",
    "newdates, prevdate = write_new_data(categ, newdata)\n",
    "print(\"newdates\", newdates)\n",
    "if len(newdates):\n",
    "    delete_prev_files(prevdate, categ) # not actually deleting rn\n",
    "    remove_prevdate_from_record(prevdate, categ)\n",
    "\n",
    "    for date in sorted(newdates):\n",
    "        print('doing date', date)\n",
    "        prevlink = add_to_record_get_prevlink(date, categ)\n",
    "        print(\"prevlink\", prevlink)\n",
    "        df = read_data_csv_date(date, categ)\n",
    "        print(\"len of df\", len(df))\n",
    "        print(df.head())\n",
    "        write_table_md(df, date, categ, prevlink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_mdfiles():\n",
    "    files = []\n",
    "    for path in Path('categories').rglob('*.md'):\n",
    "        files.append(str(path))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_all_csv_files(categs):\n",
    "    files = defaultdict(list)\n",
    "    for categ in categs:\n",
    "        for path in Path(f\"_data/{categ}/\").rglob('*.csv'):\n",
    "            if 'written' not in str(path):\n",
    "                files[categ].append(str(path))\n",
    "        files[categ] = sorted(files[categ], reverse=False)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'story': ['_data/story/2021-01-05-story-24.csv'],\n",
       "             'table2text': ['_data/table2text/2020-07-13-table2text-100.csv',\n",
       "              '_data/table2text/2021-01-17-table2text-83.csv'],\n",
       "             'games': ['_data/games/2020-11-15-games-14.csv'],\n",
       "             'dialogue': ['_data/dialogue/2020-12-29-dialogue-100.csv',\n",
       "              '_data/dialogue/2020-12-31-dialogue-2.csv'],\n",
       "             'knowledge': ['_data/knowledge/2020-04-17-knowledge-100.csv',\n",
       "              '_data/knowledge/2021-01-17-knowledge-83.csv'],\n",
       "             'poetry': ['_data/poetry/2020-09-25-poetry-14.csv'],\n",
       "             'image2text': ['_data/image2text/2020-09-28-image2text-100.csv',\n",
       "              '_data/image2text/2021-01-17-image2text-14.csv']})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvfiles = get_all_csv_files(categs)\n",
    "csvfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-05 story 24\n",
      "2020-07-13 table2text 100\n",
      "2021-01-17 table2text 83\n",
      "2020-11-15 games 14\n",
      "2020-12-29 dialogue 100\n",
      "2020-12-31 dialogue 2\n",
      "2020-04-17 knowledge 100\n",
      "2021-01-17 knowledge 83\n",
      "2020-09-25 poetry 14\n",
      "2020-09-28 image2text 100\n",
      "2021-01-17 image2text 14\n"
     ]
    }
   ],
   "source": [
    "# create the written csv record file\n",
    "written = []\n",
    "for categ, files in csvfiles.items():\n",
    "    category = categ\n",
    "    for i, file in enumerate(files):\n",
    "        (date, _, _) = parse_filename(file)\n",
    "        md_filename = f\"categories/{categ}/{date}-{categ}.md\"\n",
    "        generated_file = make_entry_for_md(date, category)\n",
    "        written.append({'date': date, 'category': category, 'md_filename': md_filename, 'generated_file': generated_file, 'data_file': file, 'most_recent': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2021-01-05',\n",
       "  'category': 'story',\n",
       "  'md_filename': 'categories/story/2021-01-05-story.md',\n",
       "  'generated_file': '_site/categories/story/2021/01/05/story.html',\n",
       "  'data_file': '_data/story/2021-01-05-story-24.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2020-07-13',\n",
       "  'category': 'table2text',\n",
       "  'md_filename': 'categories/table2text/2020-07-13-table2text.md',\n",
       "  'generated_file': '_site/categories/table2text/2020/07/13/table2text.html',\n",
       "  'data_file': '_data/table2text/2020-07-13-table2text-100.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2021-01-17',\n",
       "  'category': 'table2text',\n",
       "  'md_filename': 'categories/table2text/2021-01-17-table2text.md',\n",
       "  'generated_file': '_site/categories/table2text/2021/01/17/table2text.html',\n",
       "  'data_file': '_data/table2text/2021-01-17-table2text-83.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2020-11-15',\n",
       "  'category': 'games',\n",
       "  'md_filename': 'categories/games/2020-11-15-games.md',\n",
       "  'generated_file': '_site/categories/games/2020/11/15/games.html',\n",
       "  'data_file': '_data/games/2020-11-15-games-14.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2020-12-29',\n",
       "  'category': 'dialogue',\n",
       "  'md_filename': 'categories/dialogue/2020-12-29-dialogue.md',\n",
       "  'generated_file': '_site/categories/dialogue/2020/12/29/dialogue.html',\n",
       "  'data_file': '_data/dialogue/2020-12-29-dialogue-100.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2020-12-31',\n",
       "  'category': 'dialogue',\n",
       "  'md_filename': 'categories/dialogue/2020-12-31-dialogue.md',\n",
       "  'generated_file': '_site/categories/dialogue/2020/12/31/dialogue.html',\n",
       "  'data_file': '_data/dialogue/2020-12-31-dialogue-2.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2020-04-17',\n",
       "  'category': 'knowledge',\n",
       "  'md_filename': 'categories/knowledge/2020-04-17-knowledge.md',\n",
       "  'generated_file': '_site/categories/knowledge/2020/04/17/knowledge.html',\n",
       "  'data_file': '_data/knowledge/2020-04-17-knowledge-100.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2021-01-17',\n",
       "  'category': 'knowledge',\n",
       "  'md_filename': 'categories/knowledge/2021-01-17-knowledge.md',\n",
       "  'generated_file': '_site/categories/knowledge/2021/01/17/knowledge.html',\n",
       "  'data_file': '_data/knowledge/2021-01-17-knowledge-83.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2020-09-25',\n",
       "  'category': 'poetry',\n",
       "  'md_filename': 'categories/poetry/2020-09-25-poetry.md',\n",
       "  'generated_file': '_site/categories/poetry/2020/09/25/poetry.html',\n",
       "  'data_file': '_data/poetry/2020-09-25-poetry-14.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2020-09-28',\n",
       "  'category': 'image2text',\n",
       "  'md_filename': 'categories/image2text/2020-09-28-image2text.md',\n",
       "  'generated_file': '_site/categories/image2text/2020/09/28/image2text.html',\n",
       "  'data_file': '_data/image2text/2020-09-28-image2text-100.csv',\n",
       "  'most_recent': False},\n",
       " {'date': '2021-01-17',\n",
       "  'category': 'image2text',\n",
       "  'md_filename': 'categories/image2text/2021-01-17-image2text.md',\n",
       "  'generated_file': '_site/categories/image2text/2021/01/17/image2text.html',\n",
       "  'data_file': '_data/image2text/2021-01-17-image2text-14.csv',\n",
       "  'most_recent': False}]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_most_recent(written_df):\n",
    "    firsts = written_df.sort_values(by=['category', 'date'], ascending=False).groupby('category').first().reset_index()\n",
    "    for i, row in firsts.iterrows():\n",
    "        written_df.loc[(written_df['category'] == row['category']) & (written_df['date'] == row['date']), 'most_recent'] = True\n",
    "    return written_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "written_df = pd.DataFrame(written)\n",
    "written_df['prev_link'] = None\n",
    "written_df = set_most_recent(written_df)\n",
    "\n",
    "# set the prev links in the file\n",
    "for categ in categs:\n",
    "    written_df.loc[written_df['category']==categ].sort_values(by=\"date\", ascending=True, inplace=True)\n",
    "    shifted = written_df[written_df['category']==categ].shift(1)['generated_file']\n",
    "    written_df.loc[ written_df['category']==categ, 'prev_link'] = shifted\n",
    "\n",
    "written_df.to_csv(\"_data/files_written.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>md_filename</th>\n",
       "      <th>generated_file</th>\n",
       "      <th>data_file</th>\n",
       "      <th>most_recent</th>\n",
       "      <th>prev_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>story</td>\n",
       "      <td>categories/story/2021-01-05-story.md</td>\n",
       "      <td>_site/categories/story/2021/01/05/story.html</td>\n",
       "      <td>_data/story/2021-01-05-story-24.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>table2text</td>\n",
       "      <td>categories/table2text/2020-07-13-table2text.md</td>\n",
       "      <td>_site/categories/table2text/2020/07/13/table2t...</td>\n",
       "      <td>_data/table2text/2020-07-13-table2text-100.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>table2text</td>\n",
       "      <td>categories/table2text/2021-01-17-table2text.md</td>\n",
       "      <td>_site/categories/table2text/2021/01/17/table2t...</td>\n",
       "      <td>_data/table2text/2021-01-17-table2text-83.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>_site/categories/table2text/2020/07/13/table2t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-15</td>\n",
       "      <td>games</td>\n",
       "      <td>categories/games/2020-11-15-games.md</td>\n",
       "      <td>_site/categories/games/2020/11/15/games.html</td>\n",
       "      <td>_data/games/2020-11-15-games-14.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>dialogue</td>\n",
       "      <td>categories/dialogue/2020-12-29-dialogue.md</td>\n",
       "      <td>_site/categories/dialogue/2020/12/29/dialogue....</td>\n",
       "      <td>_data/dialogue/2020-12-29-dialogue-100.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>dialogue</td>\n",
       "      <td>categories/dialogue/2020-12-31-dialogue.md</td>\n",
       "      <td>_site/categories/dialogue/2020/12/31/dialogue....</td>\n",
       "      <td>_data/dialogue/2020-12-31-dialogue-2.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>_site/categories/dialogue/2020/12/29/dialogue....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>categories/knowledge/2020-04-17-knowledge.md</td>\n",
       "      <td>_site/categories/knowledge/2020/04/17/knowledg...</td>\n",
       "      <td>_data/knowledge/2020-04-17-knowledge-100.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>categories/knowledge/2021-01-17-knowledge.md</td>\n",
       "      <td>_site/categories/knowledge/2021/01/17/knowledg...</td>\n",
       "      <td>_data/knowledge/2021-01-17-knowledge-83.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>_site/categories/knowledge/2020/04/17/knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>poetry</td>\n",
       "      <td>categories/poetry/2020-09-25-poetry.md</td>\n",
       "      <td>_site/categories/poetry/2020/09/25/poetry.html</td>\n",
       "      <td>_data/poetry/2020-09-25-poetry-14.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>image2text</td>\n",
       "      <td>categories/image2text/2020-09-28-image2text.md</td>\n",
       "      <td>_site/categories/image2text/2020/09/28/image2t...</td>\n",
       "      <td>_data/image2text/2020-09-28-image2text-100.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>image2text</td>\n",
       "      <td>categories/image2text/2021-01-17-image2text.md</td>\n",
       "      <td>_site/categories/image2text/2021/01/17/image2t...</td>\n",
       "      <td>_data/image2text/2021-01-17-image2text-14.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>_site/categories/image2text/2020/09/28/image2t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    category                                     md_filename  \\\n",
       "0   2021-01-05       story            categories/story/2021-01-05-story.md   \n",
       "1   2020-07-13  table2text  categories/table2text/2020-07-13-table2text.md   \n",
       "2   2021-01-17  table2text  categories/table2text/2021-01-17-table2text.md   \n",
       "3   2020-11-15       games            categories/games/2020-11-15-games.md   \n",
       "4   2020-12-29    dialogue      categories/dialogue/2020-12-29-dialogue.md   \n",
       "5   2020-12-31    dialogue      categories/dialogue/2020-12-31-dialogue.md   \n",
       "6   2020-04-17   knowledge    categories/knowledge/2020-04-17-knowledge.md   \n",
       "7   2021-01-17   knowledge    categories/knowledge/2021-01-17-knowledge.md   \n",
       "8   2020-09-25      poetry          categories/poetry/2020-09-25-poetry.md   \n",
       "9   2020-09-28  image2text  categories/image2text/2020-09-28-image2text.md   \n",
       "10  2021-01-17  image2text  categories/image2text/2021-01-17-image2text.md   \n",
       "\n",
       "                                       generated_file  \\\n",
       "0        _site/categories/story/2021/01/05/story.html   \n",
       "1   _site/categories/table2text/2020/07/13/table2t...   \n",
       "2   _site/categories/table2text/2021/01/17/table2t...   \n",
       "3        _site/categories/games/2020/11/15/games.html   \n",
       "4   _site/categories/dialogue/2020/12/29/dialogue....   \n",
       "5   _site/categories/dialogue/2020/12/31/dialogue....   \n",
       "6   _site/categories/knowledge/2020/04/17/knowledg...   \n",
       "7   _site/categories/knowledge/2021/01/17/knowledg...   \n",
       "8      _site/categories/poetry/2020/09/25/poetry.html   \n",
       "9   _site/categories/image2text/2020/09/28/image2t...   \n",
       "10  _site/categories/image2text/2021/01/17/image2t...   \n",
       "\n",
       "                                         data_file  most_recent  \\\n",
       "0              _data/story/2021-01-05-story-24.csv         True   \n",
       "1   _data/table2text/2020-07-13-table2text-100.csv        False   \n",
       "2    _data/table2text/2021-01-17-table2text-83.csv         True   \n",
       "3              _data/games/2020-11-15-games-14.csv         True   \n",
       "4       _data/dialogue/2020-12-29-dialogue-100.csv        False   \n",
       "5         _data/dialogue/2020-12-31-dialogue-2.csv         True   \n",
       "6     _data/knowledge/2020-04-17-knowledge-100.csv        False   \n",
       "7      _data/knowledge/2021-01-17-knowledge-83.csv         True   \n",
       "8            _data/poetry/2020-09-25-poetry-14.csv         True   \n",
       "9   _data/image2text/2020-09-28-image2text-100.csv        False   \n",
       "10   _data/image2text/2021-01-17-image2text-14.csv         True   \n",
       "\n",
       "                                            prev_link  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2   _site/categories/table2text/2020/07/13/table2t...  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5   _site/categories/dialogue/2020/12/29/dialogue....  \n",
       "6                                                 NaN  \n",
       "7   _site/categories/knowledge/2020/04/17/knowledg...  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10  _site/categories/image2text/2020/09/28/image2t...  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "written_df  # add lengths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>md_filename</th>\n",
       "      <th>generated_file</th>\n",
       "      <th>data_file</th>\n",
       "      <th>most_recent</th>\n",
       "      <th>prev_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>story</td>\n",
       "      <td>categories/story/2021-01-05-story.md</td>\n",
       "      <td>_site/categories/story/2021/01/05/story.html</td>\n",
       "      <td>_data/story/2021-01-05-story-24.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>table2text</td>\n",
       "      <td>categories/table2text/2020-07-13-table2text.md</td>\n",
       "      <td>_site/categories/table2text/2020/07/13/table2t...</td>\n",
       "      <td>_data/table2text/2020-07-13-table2text-100.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>table2text</td>\n",
       "      <td>categories/table2text/2021-01-17-table2text.md</td>\n",
       "      <td>_site/categories/table2text/2021/01/17/table2t...</td>\n",
       "      <td>_data/table2text/2021-01-17-table2text-83.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>_site/categories/table2text/2020/07/13/table2t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-15</td>\n",
       "      <td>games</td>\n",
       "      <td>categories/games/2020-11-15-games.md</td>\n",
       "      <td>_site/categories/games/2020/11/15/games.html</td>\n",
       "      <td>_data/games/2020-11-15-games-14.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>dialogue</td>\n",
       "      <td>categories/dialogue/2020-12-29-dialogue.md</td>\n",
       "      <td>_site/categories/dialogue/2020/12/29/dialogue....</td>\n",
       "      <td>_data/dialogue/2020-12-29-dialogue-100.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>dialogue</td>\n",
       "      <td>categories/dialogue/2020-12-31-dialogue.md</td>\n",
       "      <td>_site/categories/dialogue/2020/12/31/dialogue....</td>\n",
       "      <td>_data/dialogue/2020-12-31-dialogue-2.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>_site/categories/dialogue/2020/12/29/dialogue....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>categories/knowledge/2020-04-17-knowledge.md</td>\n",
       "      <td>_site/categories/knowledge/2020/04/17/knowledg...</td>\n",
       "      <td>_data/knowledge/2020-04-17-knowledge-100.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>categories/knowledge/2021-01-17-knowledge.md</td>\n",
       "      <td>_site/categories/knowledge/2021/01/17/knowledg...</td>\n",
       "      <td>_data/knowledge/2021-01-17-knowledge-83.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>_site/categories/knowledge/2020/04/17/knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>poetry</td>\n",
       "      <td>categories/poetry/2020-09-25-poetry.md</td>\n",
       "      <td>_site/categories/poetry/2020/09/25/poetry.html</td>\n",
       "      <td>_data/poetry/2020-09-25-poetry-14.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>image2text</td>\n",
       "      <td>categories/image2text/2020-09-28-image2text.md</td>\n",
       "      <td>_site/categories/image2text/2020/09/28/image2t...</td>\n",
       "      <td>_data/image2text/2020-09-28-image2text-100.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>image2text</td>\n",
       "      <td>categories/image2text/2021-01-17-image2text.md</td>\n",
       "      <td>_site/categories/image2text/2021/01/17/image2t...</td>\n",
       "      <td>_data/image2text/2021-01-17-image2text-14.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>_site/categories/image2text/2020/09/28/image2t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    category                                     md_filename  \\\n",
       "0   2021-01-05       story            categories/story/2021-01-05-story.md   \n",
       "1   2020-07-13  table2text  categories/table2text/2020-07-13-table2text.md   \n",
       "2   2021-01-17  table2text  categories/table2text/2021-01-17-table2text.md   \n",
       "3   2020-11-15       games            categories/games/2020-11-15-games.md   \n",
       "4   2020-12-29    dialogue      categories/dialogue/2020-12-29-dialogue.md   \n",
       "5   2020-12-31    dialogue      categories/dialogue/2020-12-31-dialogue.md   \n",
       "6   2020-04-17   knowledge    categories/knowledge/2020-04-17-knowledge.md   \n",
       "7   2021-01-17   knowledge    categories/knowledge/2021-01-17-knowledge.md   \n",
       "8   2020-09-25      poetry          categories/poetry/2020-09-25-poetry.md   \n",
       "9   2020-09-28  image2text  categories/image2text/2020-09-28-image2text.md   \n",
       "10  2021-01-17  image2text  categories/image2text/2021-01-17-image2text.md   \n",
       "\n",
       "                                       generated_file  \\\n",
       "0        _site/categories/story/2021/01/05/story.html   \n",
       "1   _site/categories/table2text/2020/07/13/table2t...   \n",
       "2   _site/categories/table2text/2021/01/17/table2t...   \n",
       "3        _site/categories/games/2020/11/15/games.html   \n",
       "4   _site/categories/dialogue/2020/12/29/dialogue....   \n",
       "5   _site/categories/dialogue/2020/12/31/dialogue....   \n",
       "6   _site/categories/knowledge/2020/04/17/knowledg...   \n",
       "7   _site/categories/knowledge/2021/01/17/knowledg...   \n",
       "8      _site/categories/poetry/2020/09/25/poetry.html   \n",
       "9   _site/categories/image2text/2020/09/28/image2t...   \n",
       "10  _site/categories/image2text/2021/01/17/image2t...   \n",
       "\n",
       "                                         data_file  most_recent  \\\n",
       "0              _data/story/2021-01-05-story-24.csv         True   \n",
       "1   _data/table2text/2020-07-13-table2text-100.csv        False   \n",
       "2    _data/table2text/2021-01-17-table2text-83.csv         True   \n",
       "3              _data/games/2020-11-15-games-14.csv         True   \n",
       "4       _data/dialogue/2020-12-29-dialogue-100.csv        False   \n",
       "5         _data/dialogue/2020-12-31-dialogue-2.csv         True   \n",
       "6     _data/knowledge/2020-04-17-knowledge-100.csv        False   \n",
       "7      _data/knowledge/2021-01-17-knowledge-83.csv         True   \n",
       "8            _data/poetry/2020-09-25-poetry-14.csv         True   \n",
       "9   _data/image2text/2020-09-28-image2text-100.csv        False   \n",
       "10   _data/image2text/2021-01-17-image2text-14.csv         True   \n",
       "\n",
       "                                            prev_link  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2   _site/categories/table2text/2020/07/13/table2t...  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5   _site/categories/dialogue/2020/12/29/dialogue....  \n",
       "6                                                 NaN  \n",
       "7   _site/categories/knowledge/2020/04/17/knowledg...  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10  _site/categories/image2text/2020/09/28/image2t...  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "written_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data(categ):\n",
    "    print(len(arts2[categ]))\n",
    "    return arts2[categ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['story', 'table2text', 'games', 'dialogue', 'knowledge', 'poetry', 'image2text'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categs = arts2.keys()\n",
    "categs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in arts2.items():\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story\n",
      "23\n",
      "33\n",
      "24\n",
      "57\n",
      "Index(['title', 'pubdate', 'id', 'authors', 'categories', 'search', 'abstract',\n",
      "       'displaydate'],\n",
      "      dtype='object')\n",
      "writing new file 2021-01-05\n",
      "table2text\n",
      "100\n",
      "244\n",
      "44\n",
      "288\n",
      "Index(['title', 'pubdate', 'id', 'authors', 'categories', 'search', 'abstract',\n",
      "       'displaydate'],\n",
      "      dtype='object')\n",
      "writing new file 2020-07-13\n",
      "writing new file 2021-01-17\n",
      "games\n",
      "10\n",
      "24\n",
      "Index(['title', 'pubdate', 'id', 'authors', 'categories', 'search', 'abstract',\n",
      "       'displaydate'],\n",
      "      dtype='object')\n",
      "writing new file 2020-11-15\n",
      "dialogue\n",
      "30\n",
      "132\n",
      "Index(['title', 'pubdate', 'id', 'authors', 'categories', 'search', 'abstract',\n",
      "       'displaydate'],\n",
      "      dtype='object')\n",
      "writing new file 2020-12-29\n",
      "writing new file 2020-12-31\n",
      "knowledge\n",
      "100\n",
      "247\n",
      "33\n",
      "280\n",
      "100\n",
      "380\n",
      "47\n",
      "427\n",
      "Index(['title', 'pubdate', 'id', 'authors', 'categories', 'search', 'abstract',\n",
      "       'displaydate'],\n",
      "      dtype='object')\n",
      "writing new file 2020-04-17\n",
      "writing new file 2021-01-17\n",
      "poetry\n",
      "10\n",
      "24\n",
      "Index(['title', 'pubdate', 'id', 'authors', 'categories', 'search', 'abstract',\n",
      "       'displaydate'],\n",
      "      dtype='object')\n",
      "writing new file 2020-09-25\n",
      "image2text\n",
      "74\n",
      "188\n",
      "74\n",
      "262\n",
      "Index(['title', 'pubdate', 'id', 'authors', 'categories', 'search', 'abstract',\n",
      "       'displaydate'],\n",
      "      dtype='object')\n",
      "writing new file 2020-09-28\n",
      "writing new file 2021-01-17\n"
     ]
    }
   ],
   "source": [
    "# trying to fix bad data files\n",
    "\n",
    "from datetime import datetime\n",
    "import more_itertools\n",
    "\n",
    "for key, vals in arts2.items():\n",
    "    files = Path(f'_data/{key}/').glob(\"*\" + key + \"*.csv\")\n",
    "    files = sorted([str(file) for file in files])\n",
    "    #merge = pd.DataFrame([])\n",
    "    merge = create_df_from_new_vals(vals)\n",
    "    print(key)\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        print(len(df))\n",
    "        merge = pd.concat([df, merge], axis=0)\n",
    "        print(len(merge))\n",
    "    #print(merge.head())\n",
    "    merge['pubdate'] = pd.to_datetime(merge['pubdate'], format='%Y-%m-%d', utc=True)\n",
    "    merge.sort_values(by=\"pubdate\", ascending=True, inplace=True)  # sort by asc in order to write the 100's first\n",
    "    merge.drop_duplicates(subset=\"id\", inplace=True)\n",
    "    print(merge.columns)\n",
    "    write_all_data_files(key, merge, tag=\"new\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote  categories/story/_posts/2021-01-05-story.md\n",
      "wrote  categories/table2text/_posts/2020-07-13-table2text.md\n",
      "wrote  categories/table2text/_posts/2021-01-17-table2text.md\n",
      "wrote  categories/games/_posts/2020-11-15-games.md\n",
      "wrote  categories/dialogue/_posts/2020-12-29-dialogue.md\n",
      "wrote  categories/dialogue/_posts/2020-12-31-dialogue.md\n",
      "wrote  categories/knowledge/_posts/2020-04-17-knowledge.md\n",
      "wrote  categories/knowledge/_posts/2021-01-17-knowledge.md\n",
      "wrote  categories/poetry/_posts/2020-09-25-poetry.md\n",
      "wrote  categories/image2text/_posts/2020-09-28-image2text.md\n",
      "wrote  categories/image2text/_posts/2021-01-17-image2text.md\n"
     ]
    }
   ],
   "source": [
    "for i, row in written_df.iterrows():\n",
    "    df = pd.read_csv(row['data_file'])\n",
    "    prevlink = row['prev_link']\n",
    "    if type(prevlink) != str:\n",
    "        prevlink = None\n",
    "    most_recent = row['most_recent']\n",
    "    write_table_md(df, row['date'], row['category'], prevlink, most_recent=most_recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
